<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title></title><link href="https://wsbctechnicalblog.github.io/" rel="alternate"></link><link href="https://wsbctechnicalblog.github.io/feeds/all.atom.xml" rel="self"></link><id>https://wsbctechnicalblog.github.io/</id><updated>2020-12-19T00:00:00-08:00</updated><entry><title>Part 1: Pipelines - Why bother and what are our nightmares and options?</title><link href="https://wsbctechnicalblog.github.io/why-pipelines-part1.html" rel="alternate"></link><published>2020-12-19T00:00:00-08:00</published><updated>2020-12-19T00:00:00-08:00</updated><author><name>Willy-Peter Schaub</name></author><id>tag:wsbctechnicalblog.github.io,2020-12-19:/why-pipelines-part1.html</id><summary type="html">&lt;p&gt;Pipelines enable engineering to continuously deliver value, map and improve their processes and workflows, promoting consistency and reliability across the organisation.&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this series we are going to invite you on our journey of grappling with hundreds of inconsistent and often conflicting continuous delivery pipelines, to evolving to unified pipelines, template-driven pipelines, and eventually self-service automation. We will break down our journey into these multiple parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Part 1: Pipelines - Why bother and what are our nightmares and options? (this)&lt;/li&gt;
&lt;li&gt;Coming soon:&lt;/li&gt;
&lt;li&gt;Part 2: Pipelines - Introduction, variables and why spaces matter&lt;/li&gt;
&lt;li&gt;Part 3: Pipelines - Basic building blocks as templates and sprinkling on telemetry&lt;/li&gt;
&lt;li&gt;Part 4: Pipelines - Magic of queue time assembly&lt;/li&gt;
&lt;li&gt;Part 5: Pipelines - Blueprints to fuel consistency and enablement&lt;/li&gt;
&lt;li&gt;Part 6: Pipelines - From CI to CD and beyond in one pipeline&lt;/li&gt;
&lt;li&gt;Part 7: Self-service automation - A dream turns into reality&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;Why Pipelines?&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;"Continuous Delivery Pipeline Value Stream Mapping The Continuous Delivery Pipeline (CDP) represents the workflows, activities, and automation needed to shepherd a new piece of functionality from ideation to an on-demand release of value to the end user."&lt;/em&gt; - © Scaled Agile, Inc.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As elluded to by the quote from Scaled Agile, we are not talking about pipelines to carry oil, but pipelines that help us automate continuous integration and delivery tasks. Examples include the automation of guardrail automations, such as SonarQube, WhiteSource, and Building Code scans and validations.&lt;/p&gt;
&lt;p&gt;&lt;img alt="CICD Pipeline" src="/images/moving-hundreds-of-pipeline-snowflakes-part1-1.png"&gt;&lt;/p&gt;
&lt;p&gt;Pipelines enable engineering to continuously deliver value, map and improve their processes and workflows, promoting consistency and reliability across the organisation.&lt;/p&gt;
&lt;h1&gt;Snowflakes&lt;/h1&gt;
&lt;p&gt;A healthy DevOps mindset promotes the line of autonomy. Above the line the organization defines its vision and governance to ensure alignment with regulatory, legal, and other requirements. Below the line the engineering teams own their process, with full autonomy to plan WHO, WHEN, and HOW they will accomplish their work.&lt;/p&gt;
&lt;p&gt;If, however, there is a lack of blueprints, design practices, and governance, each team will design and develop their pipelines slightly differently. &lt;/p&gt;
&lt;p&gt;The outcome are unique &lt;strong&gt;snowflakes&lt;/strong&gt; that promote rapid evolution (positive) and a diversity of pipelines that can become hard to maintain, support, and innovate (negative).&lt;/p&gt;
&lt;p&gt;&lt;img alt="CICD Pipeline" src="/images/moving-hundreds-of-pipeline-snowflakes-part1-2.jpg"&gt;&lt;/p&gt;
&lt;p&gt;With hundreds of continuous delivery pipelines the &lt;strong&gt;Sec&lt;/strong&gt; and &lt;strong&gt;Ops&lt;/strong&gt; in DevSecOps began to buckle detecting and fixing vulnerabilities and other guardrail leaks.&lt;/p&gt;
&lt;h1&gt;Emergence of Unified Pipelines&lt;/h1&gt;
&lt;p&gt;In 2018 we decided to grab the pipelines by their valves to tackle the spread of unique pipeline patterns by defining an &lt;strong&gt;Unified&lt;/strong&gt; &lt;a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/get-started/what-is-azure-pipelines?view=azure-devops#:~:text=%20Does%20Azure%20Pipelines%20work%20with%20my%20language,code%20to%20multiple%20targets.%20Targets%20include...%20More%20"&gt;Azure Pipeline&lt;/a&gt; design pattern. The pattern promoted the following principles:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Automate everything automatable&lt;/li&gt;
&lt;li&gt;Build once&lt;blockquote&gt;
&lt;p&gt;We encourage engineering teams to create a &lt;strong&gt;release&lt;/strong&gt; build artifact, with debug symbols published to our symbol server.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Continuous integration and delivery&lt;/li&gt;
&lt;li&gt;Continuous streamlining and improvement&lt;/li&gt;
&lt;li&gt;Maintain one build definition&lt;blockquote&gt;
&lt;p&gt;Instead of a developer and release pipeline, create &lt;strong&gt;one&lt;/strong&gt; unified pipeline that locks down the higher environments.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Maintain one release pipeline definition&lt;/li&gt;
&lt;li&gt;Scan for vulnerabilities early, often, and fail fast&lt;/li&gt;
&lt;li&gt;Streamlined approvals&lt;blockquote&gt;
&lt;p&gt;By optimising our approvals, we cut down on the complexity and delay, we inherited from previous years, decades, ... &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Test early, often, and fail fast&lt;/li&gt;
&lt;li&gt;Traceability and observability of releases&lt;blockquote&gt;
&lt;p&gt;Nobody wants a &lt;em&gt;"where did this build come from"&lt;/em&gt; treasure hunt when joining a 2AM incident call.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What followed was a mind-numbing and expensive era of aligning all snowflakes to the unified design pattern, using the Azure Pipelines GUI editor to manipulate the pipeline json-based configuration. Even though we are using re-usable &lt;a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/library/task-groups?view=azure-devops#:~:text=In%20Azure%20Pipelines%2C%20you%20can%20version%20your%20own,is%20appended%20to%20the%20task%20group%20version%20number."&gt;Task Groups&lt;/a&gt; and &lt;a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/library/variable-groups?view=azure-devops&amp;amp;tabs=yaml"&gt;Variable Groups&lt;/a&gt; we had to invest thousands of error-prone clicks - there has to be a better way!?!&lt;/p&gt;
&lt;p&gt;We managed to persue our goals of &lt;strong&gt;aligning&lt;/strong&gt; with architecture and security guardrails; &lt;strong&gt;consistency&lt;/strong&gt; through design practices, automation, and collaboration; &lt;strong&gt;simplicity&lt;/strong&gt; to create maintainable pipelines; and &lt;strong&gt;enabling&lt;/strong&gt; and &lt;strong&gt;empowering&lt;/strong&gt; our common engineering system.&lt;/p&gt;
&lt;h1&gt;Hackathon triggers a course change&lt;/h1&gt;
&lt;p&gt;A radical hackathon idea in 2019 investigated latest technology trends that promised pipeline-as-code, templates, and other facinating features that promise to enable our ultimate goal of self-service automation. Our hackathon idea was not amongst the winners, but is one of the few ideas that continued to simmer and change the world of our continuous delivery pipelines.&lt;/p&gt;
&lt;p&gt;It triggered a pipeline working group, awareness workshops, and even four laptop stickers to highlight unified pipeline, multi-stage, CI+CD, and self-service automation champions.&lt;/p&gt;
&lt;p&gt;&lt;img alt="CICD Pipeline" src="/images/moving-hundreds-of-pipeline-snowflakes-part1-3.png"&gt;&lt;/p&gt;
&lt;p&gt;Welcome YAML based pipelines, which we will introduce in Part 2 of this series.&lt;/p&gt;</content><category term="Posts"></category><category term="Azure-Pipelines"></category><category term="DevOps"></category></entry><entry><title>Shift LEFT and RIGHT to take yourself off the humbling 2AM calls</title><link href="https://wsbctechnicalblog.github.io/shift-left-2am-call.html" rel="alternate"></link><published>2020-10-24T13:13:00-07:00</published><updated>2020-10-24T13:13:00-07:00</updated><author><name>Willy-Peter Schaub</name></author><id>tag:wsbctechnicalblog.github.io,2020-10-24:/shift-left-2am-call.html</id><summary type="html">&lt;p&gt;We need to avoid the infamous 2AM call!&lt;/p&gt;</summary><content type="html">&lt;p&gt;During the &lt;strong&gt;Getting started with a DevOps mindset session&lt;/strong&gt; at the CSI Lab in January 2019, we discussed a number of epiphanies. Three referenced the 2AM call, as shown below.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Epiphanies" src="/images/two-am-call-1.png"&gt;&lt;/p&gt;
&lt;h1&gt;What is the 2AM call?&lt;/h1&gt;
&lt;p&gt;When a user reports an issue, telemetry insights identifies an anomaly, or a circuit breaker detects a potential overload, an incident is generated. On detection of the incident a call is initiated to engineers on call, also referred to as designated response individuals, who jump on the call to identify the root cause, capture vital evidence, work on a mitigation hot fix, document the incident transparently, and work with the feature teams (pods, tribes,...) to ensure that the incident never re-occurs. The reason it is called the &lt;strong&gt;2AM call&lt;/strong&gt; is that it usually happens when we are entering the REM sleep at 2AM.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;EPIPHANY 2 - The 2AM Call is a great motivation for quality&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It is obvious that no one wants to wake up at 2AM. Experiencing the 2AM call once or twice, is typically enough motivation for any of us to look for ways to improve our solution and avoid getting the dreaded call.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;EPIPHANY 3 - Teams that take ownership of features from ideation to deprecation are typically involved in the least 2AM calls.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;Why does SHIFT LEFT + SHIFT RIGHT reduce the 2AM calls?&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Epiphanies" src="/images/two-am-call-2.png"&gt;&lt;/p&gt;
&lt;h2&gt;SHIFT LEFT&lt;/h2&gt;
&lt;p&gt;The core idea is to perform tasks such as testing, security scanning, user experience reviews, and code reviews as early as possible in the continuous integration and deployment life cycle as possible. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Quick Poll" src="/images/two-am-call-3.png"&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Snapshot of our quick poll - What is important to automate for a healthy DevOps environment?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Automation is key to the &lt;strong&gt;SHIFT LEFT&lt;/strong&gt; practice allowing us to integrate the tasks seamlessly in the engineering system.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Quick Poll" src="/images/two-am-call-4.png"&gt;&lt;/p&gt;
&lt;p&gt;The above snippet is from a pull request validation build that shows that 71,283 unit tests were validated in less than 7 minutes. It can be done!&lt;/p&gt;
&lt;p&gt;Similarly, continuous integration builds can perform credential, security, and other scans, allowing us to validate the quality of a feature early and continuously, identify issues early, and either fix or fail fast before we commit ourselves to a deployment.&lt;/p&gt;
&lt;h2&gt;SHIFT RIGHT&lt;/h2&gt;
&lt;p&gt;Contrary to practices such as testing and security scanning, which we want to perform as early and often as possible, we want to defer the configuration deployments as long as possible - &lt;strong&gt;SHIFT&lt;/strong&gt; configuration &lt;strong&gt;RIGHT&lt;/strong&gt;. Explore how to generate &lt;strong&gt;ONE&lt;/strong&gt; build, deploy to &lt;strong&gt;MANY&lt;/strong&gt; environments, simplify build artifact traceability and remote debug, as needed ... it is possible!&lt;/p&gt;
&lt;h2&gt;BUT, WHY DOES IT REDUCE THE 2AM CALL?&lt;/h2&gt;
&lt;p&gt;PEOPLE are the hardest part of any transformation! Innovating continuously to improve the &lt;strong&gt;PROCESS&lt;/strong&gt; and &lt;strong&gt;PRODUCTS&lt;/strong&gt; (tools) is the easy part. &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;EPIPHANY 3 - We need to ensure that engineers see the value for SHIFT LEFT&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If you SHIFT LEFT with testing and security, the engineers, the &lt;strong&gt;PEOPLE&lt;/strong&gt;, will initially push back as the pull request validation builds take longer and associated logs and alert noise increase dramatically.  However, running 70,000 unit tests with every build, as shown above, eventually raises the quality of the solution. It is like a train that takes a while to pick up speed. Once in motion, the momentum will dramatically improve key performance indicators (KPI), such as &lt;strong&gt;lead time for change&lt;/strong&gt;, &lt;strong&gt;mean time to recover&lt;/strong&gt;, and especially &lt;strong&gt;change failure rate&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CAUTION&lt;/strong&gt; - KPIs are often not meaningful to all stakeholders. For example, mentioning a 2,604 times &lt;strong&gt;faster mean time to recover&lt;/strong&gt; metric is probably viewed with more skepticism than excitement by many business stakeholders.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Endangered" src="/images/two-am-call-5.png"&gt;&lt;/p&gt;
&lt;p&gt;A reduction in incidents and 2AM calls, however, is an easy one to unpack and understand - especially for on-call engineers now snoozing next to silent pagers and mobile phones.&lt;/p&gt;</content><category term="Posts"></category><category term="DevOps"></category><category term="DevOps-Mindset"></category></entry><entry><title>Don’t let your code talk to strangers</title><link href="https://wsbctechnicalblog.github.io/dont-let-your-code-talk-to-strangers.html" rel="alternate"></link><published>2020-10-24T10:20:00-07:00</published><updated>2020-10-24T10:20:00-07:00</updated><author><name>Alex Bunardzic</name></author><id>tag:wsbctechnicalblog.github.io,2020-10-24:/dont-let-your-code-talk-to-strangers.html</id><summary type="html">&lt;p&gt;Closer look into the principle of least knowledge&lt;/p&gt;</summary><content type="html">&lt;p&gt;We have discussed the crucial effect that cost of change has on the quality of the delivered business value. If the delivered value is expensive to change, it loses its attractiveness. In such cases, it quickly morphs from an asset into liability. We certainly don’t want to find ourselves in such disadvantageous position.&lt;/p&gt;
&lt;p&gt;Generally speaking, the most frequent cause of unchangeable code is tight coupling. During the early stages of development, coupling comes naturally, almost spontaneously. And at that stage, it appears quite harmless. We continue adding capabilities to our solution, and things appear to be going swimmingly.&lt;/p&gt;
&lt;p&gt;But there often comes a moment when we realize that we need to rearrange our code due to the newly arrived requirements or findings. It is at that point that tight coupling rears its ugly head and makes us realize that we have all but painted ourselves into a proverbial corner.&lt;/p&gt;
&lt;p&gt;Tight coupling has many underlying causes and anti-patterns. Today, we are going to take a closer look into one such anti-pattern – code talking to strangers.&lt;/p&gt;
&lt;h2&gt;Principle of least knowledge&lt;/h2&gt;
&lt;p&gt;Tight coupling happens when our code knows way more than is needed in order to do the job. At a first glance, knowing more than is needed doesn’t sound undesirable. What could be wrong with possessing excessive knowledge?&lt;/p&gt;
&lt;p&gt;Let’s try to illustrate what could get wrong by indulging in excessive knowledge by following a trivial example. Suppose we have a line of code that looks something like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;objectA.GetObjectB().GetObjectC().DoSomeSpecificThing();&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;In the line above, we see &lt;code&gt;objectA&lt;/code&gt; (i.e. an instance of &lt;code&gt;classA&lt;/code&gt;) getting &lt;code&gt;objectB&lt;/code&gt; (an instance of &lt;code&gt;classB&lt;/code&gt;). That’s perfectly fine, but the issue now arises due to the fact that &lt;code&gt;objectA&lt;/code&gt; is using &lt;code&gt;objectB&lt;/code&gt; not because &lt;code&gt;objectB&lt;/code&gt; can provide some useful capability/service to &lt;code&gt;objectA&lt;/code&gt; (which would be the normal case). &lt;code&gt;objectA&lt;/code&gt; is getting &lt;code&gt;objectB&lt;/code&gt; merely in order to expressly get to &lt;code&gt;objectC&lt;/code&gt;. Once &lt;code&gt;objectA&lt;/code&gt; gets a handle on &lt;code&gt;objectC&lt;/code&gt;, it can ask &lt;code&gt;objectC&lt;/code&gt; to do some specific thing.&lt;/p&gt;
&lt;p&gt;Why is that problematic? Granted, it is obvious that to &lt;code&gt;objectA&lt;/code&gt; a once or twice removed &lt;code&gt;objectC&lt;/code&gt; is a stranger. We do we say that &lt;code&gt;objectC&lt;/code&gt; is a stranger to &lt;code&gt;objectA&lt;/code&gt;? If &lt;code&gt;objectC&lt;/code&gt; was a friend to &lt;code&gt;objectA&lt;/code&gt;, there clearly would be no need for &lt;code&gt;objectA&lt;/code&gt; to get to talk to &lt;code&gt;objectC&lt;/code&gt; by first talking to &lt;code&gt;objectB&lt;/code&gt;. But in this case, objectA can only engage in a ‘friend of a friend’ type of interaction. And that’s when the problem with tight coupling begins!&lt;/p&gt;
&lt;p&gt;We see therefore that tight coupling materializes when we endow our code with unnecessary knowledge. In our code, objectA has the absolutely necessary knowledge of how to talk to its friend, &lt;code&gt;objectB&lt;/code&gt;. But instead of leaving it like that, we succumbed to the temptation to teach our code that there exists another object, &lt;code&gt;objectC&lt;/code&gt;, and although that object is not immediately available to our &lt;code&gt;objectA&lt;/code&gt;, it is available via our network of friends. So now our objectA gets saddled with excessive knowledge of having to know how to get to &lt;code&gt;objectC&lt;/code&gt; and how to ask it to perform some specific action.&lt;/p&gt;
&lt;p&gt;This is too much knowledge, and such excessive knowledge is making things tightly coupled, bloated and brittle.&lt;/p&gt;
&lt;h2&gt;Where is brittleness coming from?&lt;/h2&gt;
&lt;p&gt;In the above example, we perceive tight coupling in the form of an underlying assumption: every &lt;code&gt;objectB&lt;/code&gt; has access to &lt;code&gt;objectC&lt;/code&gt;. That is a dangerous assumption, as we may discover later on, after we’ve created a lot of code that relies on the above chaining of method calls that in some instances &lt;code&gt;objectB&lt;/code&gt; may not have access to &lt;code&gt;objectC&lt;/code&gt;. Maybe someone had refactored the code and had completely removed the association between &lt;code&gt;objectB&lt;/code&gt; and &lt;code&gt;objectC&lt;/code&gt;. Having to go and find all instances of the legacy code and adjust them to the new situation is a potential breeding ground for bugs. Often times there are slight variation in how are instantiated objects called (no one is guaranteeing that every developer will consistently name instance of &lt;code&gt;classA&lt;/code&gt; &lt;code&gt;objectA&lt;/code&gt; etc.) No regex on earth could be crafted that will guarantee to fish all these minor variations out. So we’d be left to manually pour over reams of code, trying to find all instances of such chained calls and then fix them manually.&lt;/p&gt;
&lt;p&gt;That’s brittleness to the umpteenth degree. And a vast breeding ground for all kinds of bugs.&lt;/p&gt;
&lt;h2&gt;Only talk to your immediate friends&lt;/h2&gt;
&lt;p&gt;To avoid the terrible anti-pattern of promiscuously talking to strangers, our code should embrace a very important constraint – talk only to your immediate friends.&lt;/p&gt;
&lt;p&gt;In the above case, &lt;code&gt;objectA&lt;/code&gt; should only confine itself to talking to objectB. If there is some useful capability/functionality that some stranger (e.g. &lt;code&gt;objectC&lt;/code&gt;) possesses that &lt;code&gt;objectA&lt;/code&gt; desperately needs, let &lt;code&gt;objectB&lt;/code&gt; be the broker between &lt;code&gt;objectA&lt;/code&gt; and &lt;code&gt;objectC&lt;/code&gt;. That way, our code becomes simple, future proof, unperturbable (and also easy testable).&lt;/p&gt;
&lt;p&gt;Let’s indulge in another quick example. Suppose we have an instance of a class &lt;code&gt;Driver&lt;/code&gt;, and that driver is steering an instance of a class &lt;code&gt;Vehicle&lt;/code&gt;). The way we implement steering is to allow the driver to talk to strangers; for example, if the driver wants to steer left, the code looks like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;driver.GetVehicle().GetSteeringMechanism().SteerLeft();&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;driver&lt;/code&gt; is talking to its immediate friend (&lt;code&gt;vehicle&lt;/code&gt;) in order to gain access to a stranger (an instance of the class &lt;code&gt;SteeringMechanism&lt;/code&gt;), so that the driver can directly manipulate the steering mechanism by sending it the command to steer left.&lt;/p&gt;
&lt;p&gt;This is the illustration of tight coupling in action. Suppose later on the instance of class SteeringMechanism (which was an instance of an automobile steering mechanism) gets replaced by an instance of a sail boat. On a sail boat, the steer left command has the opposite effect from the same command sent to a steering wheel in the car. Which means, we have inadvertently created a bug.&lt;/p&gt;
&lt;p&gt;So it is important to avoid tight coupling. Always limit the amount of knowledge your objects have. That way, your code will be clean, testable, deterministic and bug free.&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><category term="Posts"></category><category term="TDD"></category><category term="CI"></category></entry><entry><title>Collective code ownership</title><link href="https://wsbctechnicalblog.github.io/collective-code-ownership.html" rel="alternate"></link><published>2020-10-22T16:24:00-07:00</published><updated>2020-10-22T16:24:00-07:00</updated><author><name>Alex Bunardzic</name></author><id>tag:wsbctechnicalblog.github.io,2020-10-22:/collective-code-ownership.html</id><summary type="html">&lt;p&gt;Teams share collective responsibility and therefore collectively own the code&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;"In XP we don't do what we believe, we do what our measurements tell us.”&lt;/em&gt; Ron Jeffries&lt;/p&gt;
&lt;p&gt;Value stream delivery is largely based on automating business processes. In order to continuously deliver value, businesses invest in functionality. DevOps engineers are largely responsible for implementing desired functionality.
So we see that functionality is an asset. Businesses are willing to invest heavily in optimizing that asset. And the way the asset (i.e. functionality) is delivered is via shipping code.&lt;/p&gt;
&lt;p&gt;Now for the twist of lime: while functionality is obviously an asset, shipping code isn’t. Not only is shipping code not an asset, it is actually a liability. Once shipped, code needs constant babysitting. If code is not engineered properly, babysitting the shipped code may result in spiraling costs. No business will ever feel comfortable with such liability.&lt;/p&gt;
&lt;p&gt;In Extreme Programming (XP) we have a slightly different mantra (that basically talks about the same equation): Code is nothing, stories are everything.&lt;/p&gt;
&lt;h2&gt;Who does the code belong to?&lt;/h2&gt;
&lt;p&gt;In DevOps, code belongs to the product (i.e. a bundle of functionalities). Code never belongs to an individual engineer. Code may shortly belong to a project, but a product typically outlives any project, so it’s more accurate to say that code belongs to the product.
Collective ownership is often a counter-intuitive concept in software engineering, as it annuls the authorship. In traditional software development shops, workload is divvied up among engineers, and each engineer writes their own code in complete isolation. And because they write their own code, they are responsible for it, they own it, they run with it, they live and die by it.&lt;/p&gt;
&lt;p&gt;In software development shops that have evolved from the traditional shops, workload is not compartmentalized into mini silos. No silos, no turfs, no fiefdoms. In such shops, workload is centered on user stories. And each user story belongs to the entire team. That way, we avoid painting ourselves in a corner by isolating engineers from each other and then having to herd cats (with all the frightening overhead of coordinating, overseeing, synchronizing, judging and implementing correctional actions).&lt;/p&gt;
&lt;p&gt;And since each user story belongs to the team (i.e. there is no individual, named author of a user story), the code implementing that user story also belongs to the team. That way, there are no individual authors of any line of code, of any code statement.&lt;/p&gt;
&lt;h2&gt;How does that work in daily practice?&lt;/h2&gt;
&lt;p&gt;Collective code ownership may play out in variety of scenarios:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Engineers work in isolation&lt;/li&gt;
&lt;li&gt;Engineers engage in pair programming (each pair works in isolation)&lt;/li&gt;
&lt;li&gt;Engineers engage in mob programing&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In case where engineers work in isolation (i.e. each engineers goes away and spends some time coding in complete isolation from the team), collective ownership manifests in the full freedom to access, open and modify any block of code in the product repo. There are no silos, no barriers – we are talking full blown open source paradigm.&lt;/p&gt;
&lt;p&gt;In case of pair programming, similar concept applies: the repo is fully open for examination, modification and merging the changes. Same as an individual engineer doesn’t own any part of the code pulled from the repo, a pair of engineers also do not own any part of the code.
In case of mob programming, collaboration between engineers happens in real time. Coding happens in brief spurts (governed by the ‘musical chairs’ rotation where the person making the changes by typing and the person navigating the changes typically spend no more than 5 minutes per mini session). As the driver (i.e. person entering the changes) and the navigator (person, or persons instructing the driver) keep rotating, at the end of the coding session pretty much every team member has touched the code. Collectively, the team has made the most optimal decisions regarding which changes to the code to commit, push and merge to the trunk. Authorship becomes moot in such practice.&lt;/p&gt;
&lt;h2&gt;What are the prerequisites of collective code ownership?&lt;/h2&gt;
&lt;p&gt;It may not be advisable to jump in head first into collective code ownership before establishing rules of the game. In a nutshell, here are the minimum requirements for teams to successfully engage in collective code ownership:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The team has collectively created and agreed upon the coding standards&lt;/li&gt;
&lt;li&gt;The team is fully committed to using code management tool (git!)&lt;/li&gt;
&lt;li&gt;The team is doing full-on TDD, ideally also doing stringent mutation testing&lt;/li&gt;
&lt;li&gt;The team is using powerful IDE (Visual Studio or VS Code)&lt;/li&gt;
&lt;li&gt;The team is actively pursuing continuous integration (CI)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition to the above, it is important for all engineers on the team to agree to participate/contribute to the work needed to implement aspects of the functionality that may not be everyone’s area of interest. For example, a back-end engineer may not be interested in some front-end technologies, but is agreeable to participate and pick up some skills by working with domain experts on the team. Cross-training/cross-pollination goes a long way toward creating a highly performing team.&lt;/p&gt;
&lt;p&gt;Collective code ownership works best for small size teams, famously described as “two pizzas teams”. Any team that cannot be fed with two pizzas brings along added complexity; the overhead needed for maintaining team cohesion may exceed the benefits of cultivating collective code ownership.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;DevOps software engineering discipline is founded on the team concept. A team is not a group. A team is based on the concept of collective responsibility. And since each team works with user stories and turns those stories into shipping code, team collectively owns user stories as well as the code that implements them.
In a healthy team, when something goes wrong it is never “I thought SHE was going to take care of that!” Rather, it is “What do we have to do to fix that/take care of that?”&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><category term="Posts"></category><category term="DevOps"></category><category term="code"></category></entry><entry><title>The clash of Azure DevOps Kanban fields and Shared Area Paths</title><link href="https://wsbctechnicalblog.github.io/shared-area-paths.html" rel="alternate"></link><published>2020-10-22T13:13:00-07:00</published><updated>2020-10-22T13:13:00-07:00</updated><author><name>Willy-Peter Schaub</name></author><id>tag:wsbctechnicalblog.github.io,2020-10-22:/shared-area-paths.html</id><summary type="html">&lt;p&gt;Shared area paths can introduce inconsistency and confusion.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Azure Boards Kanban fields are powerful and valuable. Used in the land of shared Area Paths they can, however, introduce inconsistency and confusion that are hard to isolate and explain.&lt;/p&gt;
&lt;h1&gt;Let us explore a simple example&lt;/h1&gt;
&lt;p&gt;We define a few area paths for a hypothetical project, named &lt;strong&gt;Boards Chaos&lt;/strong&gt;. The Board Chaos area and its sub-paths are allocated to the default Boards Chaos team. Area A1, with sub-paths, and area A2, with sub-paths, are assigned to team A and B respectively. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Board Chaos" src="/images/clash-of-azdo-kanban-fields-and-shared-area-paths-1.png"&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt; that the Boards Chaos team shares area A1 and its sub-paths with team A, and area A2 and its sub-paths with team B. Assigning area Board Chaos and sub-paths to the default team is a subtle configuration, but allows us to demonstrate the challenge of shared area paths.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Team A&lt;/strong&gt; creates three stories and pulls A.1 and A.2 into the &lt;strong&gt;Active&lt;/strong&gt; column.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Team A Board" src="/images/clash-of-azdo-kanban-fields-and-shared-area-paths-2.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Team B&lt;/strong&gt; creates three stories, and pulls B.1, B.2, and B.3 into the &lt;strong&gt;Active&lt;/strong&gt;, &lt;strong&gt;Resolved&lt;/strong&gt;, and &lt;strong&gt;Closed columns&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Team B Board" src="/images/clash-of-azdo-kanban-fields-and-shared-area-paths-3.png"&gt;&lt;/p&gt;
&lt;p&gt;When we switch to team &lt;strong&gt;Board Chaos&lt;/strong&gt;, we notice that the team has customized their board, renaming the Active column to In-flight, and adding the Area 51 and Answer 42 columns. All of these three columns map to the Active work item state.&lt;/p&gt;
&lt;p&gt;So far so good - if you ignore the &lt;strong&gt;Board C...&lt;/strong&gt; &lt;strong&gt;Active&lt;/strong&gt; field on the card.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Team Chaos Board" src="/images/clash-of-azdo-kanban-fields-and-shared-area-paths-4.png"&gt;&lt;/p&gt;
&lt;p&gt;Board Chaos team drags cards A.1 from In-flight to &lt;strong&gt;Area 51&lt;/strong&gt;, and A.2 to &lt;strong&gt;Answer 42&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Area 51" src="/images/clash-of-azdo-kanban-fields-and-shared-area-paths-5.png"&gt;&lt;/p&gt;
&lt;p&gt;The team's board looks as expected, again as long as you ignore the field &lt;strong&gt;Board C...&lt;/strong&gt; &lt;strong&gt;Active&lt;/strong&gt; field on the cards.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Board Chaos" src="/images/clash-of-azdo-kanban-fields-and-shared-area-paths-6.png"&gt;&lt;/p&gt;
&lt;h1&gt;Oh, Oh, we have a problem&lt;/h1&gt;
&lt;p&gt;When the team looks at their product backlog, the anomaly becomes evident. Why are the Board Column values for B.1, A.1, and A.2 Active and not &lt;strong&gt;In-flight&lt;/strong&gt;, &lt;strong&gt;Area 51&lt;/strong&gt;, or &lt;strong&gt;Answer 42&lt;/strong&gt;?!? &lt;/p&gt;
&lt;p&gt;&lt;img alt="Incorrect Board Column Values" src="/images/clash-of-azdo-kanban-fields-and-shared-area-paths-7.png"&gt;&lt;/p&gt;
&lt;p&gt;Here is a view of Team A and the default team next to each other. Now look at the &lt;strong&gt;Board C&lt;/strong&gt; ... field on the cards, all of which point to Team A's &lt;strong&gt;Active&lt;/strong&gt; column.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Team A and Chaos side by side" src="/images/clash-of-azdo-kanban-fields-and-shared-area-paths-8.png"&gt;&lt;/p&gt;
&lt;p&gt;What is going on?!?&lt;/p&gt;
&lt;h1&gt;Works as designed&lt;/h1&gt;
&lt;p&gt;By design, the team with the longest area path wins the clash and dictates the values for the Kanban Board Column, Done, and Lane fields. In our setup, teams A and B have the longer area paths and win. &lt;strong&gt;Board Chaos/A1&lt;/strong&gt; from team A, for example, is longer than Board Chaos/ from the default team.&lt;/p&gt;
&lt;p&gt;If we have a scenario of shared area paths of equal depth, we will have non-deterministic results. Not in scope for this simple walk-through.&lt;/p&gt;
&lt;p&gt;As a result the cards show the Kanban field value Active for Team A on Board Chaos' board, not values &lt;strong&gt;In-flight&lt;/strong&gt;, &lt;strong&gt;Area 51&lt;/strong&gt;, &lt;strong&gt;Answer 42&lt;/strong&gt; as expected. &lt;/p&gt;
&lt;p&gt;So, how can we avoid this unexpected feature?&lt;/p&gt;
&lt;h1&gt;Tips to avoid the "oh, oh" moments&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Oh Oh Moment" src="/images/clash-of-azdo-kanban-fields-and-shared-area-paths-9.png"&gt;&lt;/p&gt;
&lt;h2&gt;Avoid shared areas&lt;/h2&gt;
&lt;p&gt;Stay away away from overlapping area path ownership. As this behavior is "as expected" and "works as designed", we do not expect future features to work seamlessly. &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;See https://msdn.microsoft.com/Library/vs/alm/Work/scale/scaled-agile-framework on guidance to setup enterprise projects.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Share read-only areas&lt;/h2&gt;
&lt;p&gt;Keep teams in their own contained, for example (1) Team A in Area A1 and (2) Team B in Area A2. If you need a shared area path, for example, (3) to raise awareness of and triage bugs use it as a read-only area and (4) reassign bugs to their respective area paths.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Shared Area Paths" src="/images/clash-of-azdo-kanban-fields-and-shared-area-paths-10.png"&gt;&lt;/p&gt;
&lt;h2&gt;Focus on your context&lt;/h2&gt;
&lt;p&gt;Focus on the work item types that are relevant to you and your team. If you are doing portfolio planning you should restrict your views of shared areas to &lt;strong&gt;Initiatives&lt;/strong&gt;, &lt;strong&gt;Epics&lt;/strong&gt;, and &lt;strong&gt;Features&lt;/strong&gt;. If you are part of the development, you should focus on Stories or Backlog Items.&lt;/p&gt;
&lt;p&gt;In other words &lt;strong&gt;keep it simple&lt;/strong&gt;*!&lt;/p&gt;</content><category term="Posts"></category><category term="AzDO"></category><category term="Azure-Boards"></category></entry><entry><title>Searching for common nodes across area paths</title><link href="https://wsbctechnicalblog.github.io/area-paths-and-nodes.html" rel="alternate"></link><published>2020-10-21T13:13:00-07:00</published><updated>2020-10-21T13:13:00-07:00</updated><author><name>Willy-Peter Schaub</name></author><id>tag:wsbctechnicalblog.github.io,2020-10-21:/area-paths-and-nodes.html</id><summary type="html">&lt;p&gt;How can we find area path with specific text in their name?&lt;/p&gt;</summary><content type="html">&lt;p&gt;Let us assume that you have a common node, for example architecture runway, in a number of Azure DevOps area paths. &lt;/p&gt;
&lt;p&gt;A common question in such a setup is "what are all the architecture runway work items?". &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Simple&lt;/strong&gt;, create a query that searches for all the known area paths:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Area Paths" src="/images/searching-for-common-nodes-across-area-paths-1.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Simple?&lt;/strong&gt; It is not a query that can scale or that anyone wants to maintain, because the only options we have for Area Paths is the equals (=) or under 
operator. Imagine you walk up to a project containing hundreds of area paths and you need to build such a query from scratch ... run!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stop!&lt;/strong&gt; There is another way, using the Node Name:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Node Names" src="/images/searching-for-common-nodes-across-area-paths-2.png"&gt;&lt;/p&gt;
&lt;p&gt;Go &lt;a href="https://docs.microsoft.com/en-us/azure/devops/boards/queries/query-by-area-iteration-path?view=azure-devops#node-name-and-keyword-based-queries"&gt;here&lt;/a&gt; for more related gems and information!&lt;/p&gt;</content><category term="Posts"></category><category term="AzDO"></category><category term="Azure-Boards"></category><category term="Tips"></category></entry><entry><title>Use Active Directory Groups in your unified classic CI CD pipelines</title><link href="https://wsbctechnicalblog.github.io/ad-groups-for-ci-cd-pipelines.html" rel="alternate"></link><published>2020-10-20T13:13:00-07:00</published><updated>2020-10-20T13:13:00-07:00</updated><author><name>Willy-Peter Schaub</name></author><id>tag:wsbctechnicalblog.github.io,2020-10-20:/ad-groups-for-ci-cd-pipelines.html</id><summary type="html">&lt;p&gt;Instead of managing permissions for users in Azure DevOps, we use Azure Active Directory groups to fine tune permissions&lt;/p&gt;</summary><content type="html">&lt;p&gt;The CI/CD pipeline is a DevOps practice for delivering code changes more frequently, consistently, and reliably. It enables Agile teams to increase deployment frequency, decrease lead time for change, change failure rate, and mean time to recovery key performance indicators, thereby improving quality and delivering value faster.&lt;/p&gt;
&lt;h1&gt;Let us use Active Directory (AD) security groups&lt;/h1&gt;
&lt;p&gt;After our dream for One CI/CD pipeline to rule them all we decided to go one-step further and simplify the classic release pipeline security using Active Directory (AD) groups. Instead of assigning and managing permissions for users in Azure DevOps, we use Azure Active Directory groups to fine tune permissions. For example, we have project specific super users AD groups that grant elevated permissions to edit release pipelines and the development and system test stages.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Classic Pipeline" src="/images/use-ad-groups-with-CI-CD-pipelines-1.png"&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Empower the Agile Development Team to own development and system test stages&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Bookmark the Azure DevOps DRIFT project, which will enable you to monitor and remediate configuration drift, for example to automatically remove explicit user accounts added to an AD driven security model.&lt;/p&gt;
&lt;h1&gt;Why AD groups?&lt;/h1&gt;
&lt;p&gt;The value of using AD groups depends on your environment. In our case the benefits are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AD groups and memberships are centrally &lt;strong&gt;managed&lt;/strong&gt; and &lt;strong&gt;audited&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;AD group membership is track than individual user accounts spread across multiple Azure DevOps services and projects.&lt;/li&gt;
&lt;li&gt;Azure DevOps users are empowered to request group membership using an existing process, rather than relying on the Azure DevOps project collection and project administrators.&lt;/li&gt;
&lt;li&gt;Simplifies automation of pipeline generation and configuration.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="Simplicity" src="/images/use-ad-groups-with-CI-CD-pipelines-2.png"&gt;&lt;/p&gt;
&lt;h1&gt;Let us use email-enabled Active Directory (AD) security groups&lt;/h1&gt;
&lt;p&gt;However, wait, we can go a step further and use mail-enabled AD security groups for pre- and post-stage pipeline approvals.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Post deployment conditionse" src="/images/use-ad-groups-with-CI-CD-pipelines-3.png"&gt;&lt;/p&gt;
&lt;p&gt;Use email-enables security groups for stage approvals
We replace the individual users highlighted in yellow with Release Approval AD groups.&lt;/p&gt;
&lt;p&gt;&lt;img alt="CI CD pipelines" src="/images/use-ad-groups-with-CI-CD-pipelines-4.png"&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Simplify stage approvals with email-enabled AD security groups&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Why are there no stage approval notifications?
We realized that some of our email-enabled AD security groups received no notifications and spend time with Microsoft support to identify the root cause(s).&lt;/p&gt;
&lt;p&gt;You have to ensure that the AD security groups:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Are &lt;strong&gt;mail-enabled&lt;/strong&gt; and authorized to receive external emails.&lt;/li&gt;
&lt;li&gt;Have &lt;strong&gt;View Releases&lt;/strong&gt; permissions on release and definitions.&lt;/li&gt;
&lt;li&gt;Have a subscription that is enabled for the group(s).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The second bullet is the one that caught us off guard. If the permission is missing the Azure DevOps Pipeline event/notification service filters out the account's notifications. When notifications are filtered, no email is sent for impacted group(s) - silence prevails.&lt;/p&gt;
&lt;p&gt;Make sure that your email-enabled AD security groups are members of your project &lt;strong&gt;Contributors or Readers&lt;/strong&gt;, which by default, have the View Releases permission.&lt;/p&gt;
&lt;h1&gt;What Is Next?&lt;/h1&gt;
&lt;p&gt;This is likely one of the last posts on classic CI/CD pipelines. Watch the space for unified multi-stage YAML-based pipeline learnings.&lt;/p&gt;</content><category term="Posts"></category><category term="Azure AD"></category><category term="Azure-Pipelines"></category></entry><entry><title>Use the move to team project feature with caution!</title><link href="https://wsbctechnicalblog.github.io/the-move-to-team-project-feature.html" rel="alternate"></link><published>2020-10-20T13:13:00-07:00</published><updated>2020-10-20T13:13:00-07:00</updated><author><name>Willy-Peter Schaub</name></author><id>tag:wsbctechnicalblog.github.io,2020-10-20:/the-move-to-team-project-feature.html</id><summary type="html">&lt;p&gt;The "Move to Team Project" feature can reset your work item state and dates&lt;/p&gt;</summary><content type="html">&lt;p&gt;There are two valuable features in the Azure Boards service, one to change the work item type and the other to move work items between projects. However ... there is always a but ... the second comes with a few gotchas that turned a simple migration into a mind-numbing slog.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Move to Team project featute" src="/images/move-to-team-project-warning-1.png"&gt;&lt;/p&gt;
&lt;p&gt;The "&lt;strong&gt;Move to team project&lt;/strong&gt;" allows you to select one, more, or all of the work items on a backlog or from a work item query language (WIQL) result set and move them to another Azure DevOps project, within the same Azure DevOps organization.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Quick and simple!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;However ... here we go again ... when you look at the migrated data you will notice two things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The work item state is reset to New&lt;/li&gt;
&lt;li&gt;The Change Date is set to the migration date and time&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Why? Do not know, but would love to understand the reasoning behind the state and date changes. If you have not planned your migration you will not have to single step through hundreds to thousands of work items to determine the correct state and dates - mind numbing!&lt;/p&gt;
&lt;h1&gt;Pre-migration planning&lt;/h1&gt;
&lt;p&gt;After staring at the updated work item data in disbelief a few times, we have created a simple pre-migration checklist:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Export all work items to an Excel workbook to have a reference snapshot.&lt;/li&gt;
&lt;li&gt;Tag the work items with the state, iteration, board column, and board lane.&lt;/li&gt;
&lt;li&gt;Verify that target has all of the work item types for the set of items you need to migrate&lt;/li&gt;
&lt;li&gt;Grab a can of your favourite brew ... you will need it!&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Post-migration grooming&lt;/h1&gt;
&lt;p&gt;After using the "Move to team project" feature to migrate all of the work items, we process the post-migration checklist:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set the correct state of the work items, based on the state tag. Once done, remove tag.&lt;/li&gt;
&lt;li&gt;Set the correct Iteration Path, based on the state tag. Once done, remove tag.&lt;/li&gt;
&lt;li&gt;Move cards to the correct column and swim lane, based on the column and lane tags. Once done, remove tags.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If needed, set the correct Activated and Closed dates, which are now set to the date and time when you corrected the work item state :(
PowerShell Script to the Rescue&lt;/p&gt;
&lt;h1&gt;Samples&lt;/h1&gt;
&lt;p&gt;Here are two sample scripts we added to our ever-growing library of automation and maintenance scripts to update the read-only Closed Date field. We want to change the dates back to the post migration dates, which we can extract from the Excel workbook we created in pre-migration step 1, so that the data on boards and the backlog looks valid.&lt;/p&gt;
&lt;h2&gt;Set Changed Date Script&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[CmdletBinding()]&lt;/span&gt;
&lt;span class="na"&gt;param(&lt;/span&gt;
  &lt;span class="na"&gt;[string]   $orgName&lt;/span&gt;       &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;lt;ORG&amp;gt;&amp;quot;,&lt;/span&gt;
&lt;span class="s"&gt;  [string]   $patToken      = &amp;quot;&amp;lt;PAT&amp;gt;&amp;quot;,&lt;/span&gt;
&lt;span class="s"&gt;  [string]   $workItemID    = &amp;quot;&amp;lt;invalid&amp;gt;&amp;quot;,&lt;/span&gt;
&lt;span class="s"&gt;  [string]   $dateTime      = &amp;quot;&amp;lt;invalid&amp;gt;&amp;quot;&lt;/span&gt;
&lt;span class="na"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Authentication header&lt;/span&gt;
&lt;span class="na"&gt;$basicAuth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;(&amp;quot;{0}:{1}&amp;quot; -f &amp;quot;&amp;quot;,$patToken)&lt;/span&gt;
&lt;span class="na"&gt;$basicAuth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;[System.Text.Encoding]::UTF8.GetBytes($basicAuth)&lt;/span&gt;
&lt;span class="na"&gt;$basicAuth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;[System.Convert]::ToBase64String($basicAuth)&lt;/span&gt;
&lt;span class="na"&gt;$headers&lt;/span&gt;   &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;@{Authorization=(&amp;quot;Basic {0}&amp;quot; -f $basicAuth)}&lt;/span&gt;

&lt;span class="c1"&gt;# Setup Request&lt;/span&gt;
&lt;span class="na"&gt;$request&lt;/span&gt;   &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;https://dev.azure.com/&amp;quot; + $orgName + &amp;quot;/&amp;quot; + &amp;quot;_apis/wit/workitems/&amp;quot; + $workItemID + &amp;quot;?bypassRules=true&amp;amp;api-version=6.0&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# Setup Body&lt;/span&gt;
&lt;span class="na"&gt;$json&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; 
&lt;span class="na"&gt;&amp;#39;[&lt;/span&gt;
&lt;span class="na"&gt;{&amp;quot;op&amp;quot;:&amp;quot;add&amp;quot;,&amp;quot;path&amp;quot;:&amp;quot;/fields/Microsoft.VSTS.Common.ClosedDate&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;&amp;#39; + $dateTime + &amp;#39;&amp;quot;},&lt;/span&gt;
&lt;span class="na"&gt;{&amp;quot;op&amp;quot;:&amp;quot;add&amp;quot;,&amp;quot;path&amp;quot;:&amp;quot;/fields/System.History&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;Post-migration Closed Date correction to reflect original, not migration, date.&amp;quot;}&lt;/span&gt;
&lt;span class="na"&gt;]&amp;#39;&lt;/span&gt;

&lt;span class="c1"&gt;# Call Request&lt;/span&gt;
&lt;span class="na"&gt;try&lt;/span&gt;
&lt;span class="na"&gt;{&lt;/span&gt;
  &lt;span class="na"&gt;Write-Host &amp;quot;Updating work item: $workItemID&amp;quot;&lt;/span&gt;
  &lt;span class="na"&gt;$response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;Invoke-RestMethod -Uri $request -headers $headers -Method PATCH -Body $json -ContentType &amp;#39;application/json-patch+json&amp;#39;&lt;/span&gt;
&lt;span class="na"&gt;}&lt;/span&gt;
&lt;span class="na"&gt;catch &lt;/span&gt;
&lt;span class="na"&gt;{&lt;/span&gt;
    &lt;span class="na"&gt;Write-Host &amp;quot;Error setting date - &amp;quot; $PSItem.Exception.Message&lt;/span&gt;
    &lt;span class="na"&gt;Write-Host  $_.Exception|format-list -force&lt;/span&gt;
&lt;span class="na"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Calling Script&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;# Batch 1&lt;/span&gt;
&lt;span class="err"&gt;..\Scripts\Update_Work_Item_ClosedDate.ps1 -orgName &amp;quot;&amp;lt;ORG&amp;gt;&amp;quot; -patToken &amp;quot;&amp;lt;PAT&amp;gt;&amp;quot; -workItemID &amp;quot;&amp;lt;WI #&amp;gt;&amp;quot; -dateTime &amp;quot;&amp;lt;DATE FROM EXCEL WORKBOOK&amp;gt;T13:00:00.00-08:00&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;..\Scripts\Update_Work_Item_ClosedDate.ps1 -orgName &amp;quot;&amp;lt;ORG&amp;gt;&amp;quot; -patToken &amp;quot;&amp;lt;PAT&amp;gt;&amp;quot; -workItemID &amp;quot;&amp;lt;WI #&amp;gt;&amp;quot; -dateTime &amp;quot;&amp;lt;DATE FROM EXCEL WORKBOOK&amp;gt;T13:00:00.00-08:00&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Migrating data is not an easy task, especially if you also need to migrate Test Plans, Suites, and Cases ... that is another turbulent topic for another day. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Migration Tools for Azure DevOps" src="/images/move-to-team-project-warning-2.png"&gt;&lt;/p&gt;
&lt;p&gt;We are busy investigating the open source Migration Tools for Azure DevOps, by Martin Hinshelwood, which will hopefully allow us to further automate and reduce the number of state changes during work item migrations. I will be back with an update!&lt;/p&gt;</content><category term="Posts"></category><category term="AzDO"></category><category term="Azure-Boards"></category></entry><entry><title>Pull Request is your friend not foe!</title><link href="https://wsbctechnicalblog.github.io/pull-requests-friend.html" rel="alternate"></link><published>2020-10-19T13:13:00-07:00</published><updated>2020-10-19T13:13:00-07:00</updated><author><name>Willy-Peter Schaub</name></author><id>tag:wsbctechnicalblog.github.io,2020-10-19:/pull-requests-friend.html</id><summary type="html">&lt;p&gt;There is a debate around the value of pull requests (PR), fueled by unfortunate misunderstandings.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;"The primary reason we use PRs is to encourage quality in the commits that are made to our code repositories"&lt;/em&gt; - &lt;a href="https://gist.github.com/mikepea/863f63d6e37281e329f8"&gt;GitHub Pull request Etiguette&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Start simple&lt;/h1&gt;
&lt;p&gt;Let us start with a simple branching strategy, with one "always" deployable target branch (master/main/trunk), and a short-lived feature branch, as shown below.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Feature Branch" src="/images/Pull-Request-is-your-friend-not-foe-1.jpg"&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create a short-lived feature branch.&lt;/li&gt;
&lt;li&gt;Work on new work or a bug fix.&lt;/li&gt;
&lt;li&gt;Merge (commit) changes to the target branch.&lt;/li&gt;
&lt;li&gt;Continuous Integration (CI) build is triggered.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="Caution" src="/images/Pull-Request-is-your-friend-not-foe-2.png"&gt;&lt;/p&gt;
&lt;p&gt;Simple, but potentially dangerous. As the CI build is triggered after changes have been committed to the target branch, we could have a broken build and an undeployable branch. To make matters worse, anyone creating a new feature branch from an undeployable branch has just inherited a lot of unproductive pain!&lt;/p&gt;
&lt;h1&gt;Embrace the four-eyes principle&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Four-Eyes Principle" src="/images/Pull-Request-is-your-friend-not-foe-3.jpg"&gt;&lt;/p&gt;
&lt;p&gt;The four-eyes principle requires that at least four eyes, in other words, validate any change by at least two people. With &lt;a href="https://docs.microsoft.com/en-us/azure/devops/user-guide/what-is-azure-devops?view=azure-devops"&gt;Azure DevOps&lt;/a&gt; we can define &lt;a href="https://docs.microsoft.com/en-us/azure/devops/repos/git/branch-policies-overview?view=azure-devops"&gt;Branch Policies&lt;/a&gt; to protect target branches, such as requiring:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Minimum number of reviewers (required and optional)&lt;/li&gt;
&lt;li&gt;Linked work items (adds the context and traceability)&lt;/li&gt;
&lt;li&gt;Resolved comments (all discussions and recommendations actioned)&lt;/li&gt;
&lt;li&gt;Limited merge types&lt;/li&gt;
&lt;li&gt;Successful build (which includes security scans, tests, etc.)&lt;/li&gt;
&lt;li&gt;Thumbs up from other services&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;We can require some or all of the above policies.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;Welcome Pull Request&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;Pull Request is a change validation workflow, not a feature of the version control service.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="Welcome" src="/images/Pull-Request-is-your-friend-not-foe-4.png"&gt;&lt;/p&gt;
&lt;p&gt;When we define one or more branch policies, we enforce them on &lt;a href="https://docs.microsoft.com/en-us/azure/devops/repos/git/pull-requests?view=azure-devops"&gt;Pull Requests&lt;/a&gt;, making it impossible for anyone to commit changes to our target branch without passing pre-defined validations.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;By excluding minimum number of reviewers and setting our pull request to auto-complete, we could commit our changes without any human intervention if and only if we pass all other validations. However, that is a topic for another day.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let us walk through the same branching strategy, as above, and observe how the Pull Request enables (optional) collaboration and required validations.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Pull Request Workflow" src="/images/Pull-Request-is-your-friend-not-foe-5.jpg"&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create a short-lived feature branch.&lt;/li&gt;
&lt;li&gt;Work on new work or a bug fix.&lt;/li&gt;
&lt;li&gt;Create a &lt;strong&gt;DRAFT&lt;/strong&gt; pull request, which enables collaboration, work item linking, and manual build validation policies.&lt;/li&gt;
&lt;li&gt;When we are ready to have our pull request reviewed and completed, we can &lt;strong&gt;PUBLISH&lt;/strong&gt; our draft pull request.&lt;/li&gt;
&lt;li&gt;Pre-defined optional and required reviewers are assigned and notified, policies are evaluated, and voting is enabled. The validation builds are triggered and perform a pre-merge validation - if the build(s) fail, the Pull Request cannot be completed.&lt;/li&gt;
&lt;li&gt;When all policies are met, the Pull Request can be completed.&lt;/li&gt;
&lt;li&gt;Associated changes are merged to the target branch.&lt;/li&gt;
&lt;li&gt;Which, as before, triggers the continuous integration (CI) build.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We do not have to create a DRAFT Pull Request. Instead, we can combine steps 3 and 4 above.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Recommendation 1 - Create one build definition and re-use it for both the validation and the CI build. Consistent and simple!&lt;/p&gt;
&lt;p&gt;Recommendation 2 - Run security scans, such as SonarQube and WhiteSource, Tests, and other quality validations in either the validation or CI build. We chose to run all validations when the common build is triggered as a validation build, as we need the results to review the changes effectively. See YAML sample below.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The advantages of Pull Requests are evident:
- Collaboration is enabled fostering sharing of experience, learning, and recording of discussions.
- Guardrail are validated and enforced
- Automation of validations, which could (or not) include humanoid involvement&lt;/p&gt;
&lt;h1&gt;YAML Sample&lt;/h1&gt;
&lt;p&gt;Last, but not least, here is the above-mentioned extract from one of our YAML pipelines. The conditional code ensures that custom validations are injected into our build only if it was triggered as a validation build in a Pull Request.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# VALIDATIONS&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt;  &lt;span class="n"&gt;eq&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;variables&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Build.SourceBranchName&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;merge&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;}}:&lt;/span&gt;    
  &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;template&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;DSO&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;InjectValidations&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;yml&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;</content><category term="Posts"></category><category term="AzDO"></category><category term="Azure-Repos"></category><category term="Git"></category></entry><entry><title>Benefits of boundaries</title><link href="https://wsbctechnicalblog.github.io/benefits-of-boundaries.html" rel="alternate"></link><published>2020-10-19T10:20:00-07:00</published><updated>2020-10-19T10:20:00-07:00</updated><author><name>Alex Bunardzic</name></author><id>tag:wsbctechnicalblog.github.io,2020-10-19:/benefits-of-boundaries.html</id><summary type="html">&lt;p&gt;Simple isn't easy, but it is the only way to build anti-fragile systems&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;Things break on a small scale all the time, in order to avoid large-scale generalized catastrophes.”&lt;/em&gt; — Nassim Nicholas Taleb&lt;/p&gt;
&lt;p&gt;Right on the heels of our PI Planning session, I’d like to continue the discussion on the merits of imposing and maintaining boundaries. To recapitulate what we talked about thus far:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Systems are under constant stress (regulatory changes, market shifts, pandemics, customer expectations drift, and also plain old digital rot)&lt;/li&gt;
&lt;li&gt;Monoliths are brittle, and are first to crumble under the stresses and shocks of relentless change&lt;/li&gt;
&lt;li&gt;System resilience is 100% dependent on the system architecture&lt;/li&gt;
&lt;li&gt;System architecture can enable a system to survive stress&lt;/li&gt;
&lt;li&gt;Three main types of system architecture:&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Robust architecture&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Agile architecture&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Anti-fragile architecture&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Anti-fragile architecture is the most advanced/biggest bang for the buck&lt;/li&gt;
&lt;li&gt;It hinges on boundaries&lt;/li&gt;
&lt;li&gt;It is anti-fragile because it enables the system to function by safely engaging in trial-and-error&lt;/li&gt;
&lt;li&gt;It focuses on small problems&lt;/li&gt;
&lt;li&gt;It allows only small errors to occur&lt;/li&gt;
&lt;li&gt;It puts pressure on the system without jeopardizing it&lt;/li&gt;
&lt;li&gt;When the pressure gets fixed and removed, the system grows stronger than before (e.g. Netflix Chaos Monkey anti-fragile architecture)&lt;/li&gt;
&lt;li&gt;It enables the business to embrace change&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Why bother introducing boundaries?&lt;/h2&gt;
&lt;p&gt;There is plenty of field evidence illustrating the fact that any large, complex system that works according to expectations was once a small, simple system that gradually evolved into a larger one. Conversely, there is no evidence that a system that started as large and complex ever reached the point of being fully functional.&lt;/p&gt;
&lt;p&gt;As a small, simple system evolves and grows, it can only do so by containment. The most fundamental principle of software design is to separate things that change from things that stay the same. This isolation (containment) is not a one-time event. Keeping things contained/isolated is an ongoing design activity which must occur every step of the way.&lt;/p&gt;
&lt;p&gt;And the only way to keep things contained is to introduce and maintain boundaries.&lt;/p&gt;
&lt;h2&gt;Would any boundaries do?&lt;/h2&gt;
&lt;p&gt;The short (and not so sweet) answer is: no. The hardest (and most powerful) trick is knowing where and how to erect boundaries. That knowledge is what separates experienced experts from dilettante software designers.&lt;/p&gt;
&lt;p&gt;Let's have a quick look into a system that was architected using the wrong boundaries pattern:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Incorrect boundaries pattern" src="/images/boundaries1.png"&gt; &lt;/p&gt;
&lt;p&gt;What is wrong with the above picture? Infrastructure layers should never be used to create boundaries for top level modules.&lt;/p&gt;
&lt;p&gt;Let’s now look into a system that was architected using proper boundaries pattern:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Proper boundaries pattern" src="/images/boundaries2.png"&gt; &lt;/p&gt;
&lt;h2&gt;Boundary fitness&lt;/h2&gt;
&lt;p&gt;As difficult as it often may be to create proper boundaries (it takes a lot of experience before one is capable of designing the system correctly), it is much, much harder to keep the boundaries intact.&lt;/p&gt;
&lt;p&gt;As the system evolves, there is a strong tendency to break the boundaries. It is very tempting, as we are developing new features (or extending existing features) to take shortcuts and try to access modules that belong to isolated layers. Any time we do that, we are diluting the separation of concerns.&lt;/p&gt;
&lt;p&gt;Boundary fitness is therefore expressed as a metric of how much of the important architectural characteristics remain preserved as the system evolves. Protecting the purity of the boundaries is of paramount importance. Whenever we encounter a system that is flakey and riddled with defects, upon closer examination we see that many, sometimes all architectural boundaries have been violated.&lt;/p&gt;
&lt;p&gt;For example, a typical anti-pattern often goes like this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Boundaries anti-pattern" src="/images/boundaries2.png"&gt; &lt;/p&gt;
&lt;p&gt;We must never make cross-boundary calls. But that is easier said than done, because in the heat of the battle, we reach for an easy solution and see that crossing over to another domain is a quick win. We do it, and thus incur technical debt. And more likely than not, that debt never gets paid off.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;It is important to avoid the Big Plan Upfront approach to building software systems. It is much more advisable to start small, and maintain small isolated parts of a larger system. Correctly choosing the boundaries ensures we start on the right footing. The biggest challenge, however, is maintaining the pristine domains within the system. It takes strong discipline to resist the urge to cross the boundaries in order to accomplish quick and dirty wins.&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><category term="Posts"></category><category term="TDD"></category><category term="CI"></category></entry><entry><title>Why extract methods when modifying legacy code?</title><link href="https://wsbctechnicalblog.github.io/why-extract-methods.html" rel="alternate"></link><published>2020-10-16T10:20:00-07:00</published><updated>2020-10-16T10:20:00-07:00</updated><author><name>Alex Bunardzic</name></author><id>tag:wsbctechnicalblog.github.io,2020-10-16:/why-extract-methods.html</id><summary type="html">&lt;p&gt;Legacy code is hard to test, so extract methods by writing micro tests&lt;/p&gt;</summary><content type="html">&lt;p&gt;Allow me a bit of introspection. I’ve been in Software Engineering field for 30 years. During those 30 years I modified a lot of legacy software. Here is how I would typically do it:&lt;/p&gt;
&lt;p&gt;Over the years I have formed certain habits when working with legacy code. Because on most projects I get paid to deliver working software that is easy to maintain, I cannot afford the luxury of taking my sweet time trying to fully understand the legacy code I am about to modify. So I tend to skim. Skimming the code helps me quickly identify relevant portions in the repo. It is a race with time, and I don’t have cycles at my disposal to dwell on less relevant minutia. I’m always going for the most relevant area in the code. Once I find it, I slow down and start analyzing it.&lt;/p&gt;
&lt;p&gt;I rely heavily on IDEs (power tools). Doesn’t matter which power tool, these days they’re all pretty much capable of doing the same thing. What’s important to me is the ability to quickly find where functions are called and where variables are used.&lt;/p&gt;
&lt;p&gt;Sooner or later, after I’m done skimming the code and analyzing the code segment I’m intending to change, I identify a place where I want to insert some code. Now that I understand the meaning of the classes, components, objects involved in performing the function, I first write a test.&lt;/p&gt;
&lt;p&gt;Following that, I write code to make the test pass. I type the name of the object I intend to use, and then press the period (dot, or “.”) key. Immediately, IDE responds with giving me a full list of methods defined for that object. All those methods are callable from the location where my cursor is.&lt;/p&gt;
&lt;p&gt;I then pick the method that makes sense to me. I fill in the blanks (i.e. supply values for the expected arguments/parameters), save the change, and run the test. If the test passes, I’m done with that micro change.&lt;/p&gt;
&lt;p&gt;The above activity typically gets repeated many times per hour. Throughout the workday, it is not unusual to see the above activity repeated dozens, even hundreds of times.&lt;/p&gt;
&lt;p&gt;I believe the above description of the way I modify software is not unique to the way I formed my work habits. I believe it describes a typical flow that many (I’d even say most) software engineers adhere to.&lt;/p&gt;
&lt;h2&gt;A few observations&lt;/h2&gt;
&lt;p&gt;The first thing that is apparent after observing the above described way of modifying legacy software is the absence of any work on documentation. Experience has shown that software developers very rarely spend time reaching out for documentation. Time spent preparing the documentation and generating it to produce HTML-style online documents is time wasted.&lt;/p&gt;
&lt;p&gt;Instead, most developers rely solely upon power tools (IDEs). And rightly so (IDEs never lie, as they always offer the real-time picture of the system we are modifying; documentation is more often than not stale).&lt;/p&gt;
&lt;p&gt;Another thing worth noticing is that developers don’t read the source code the way it was written. When writing code from scratch (first pass), many developers tend to write in long functions. Source code tends to bunch up. Bunching code up makes it easier to read and reason about on the first pass, and also makes it easier to debug. But after the first pass is finished, people rarely, if ever, consume the code the way it was written. If we catch ourselves reading a whole function from beginning to end, it is most likely due to the fact that we have exhausted all other options and have no choice but to slow down and read the code in a pedestrian way. However, in my experience, that slow and orderly reading of the code seldom happens.&lt;/p&gt;
&lt;h2&gt;Problems caused by the bunched up code&lt;/h2&gt;
&lt;p&gt;If we were to leave the code as it was written during the first pass (i.e. long functions, a lot of bunched up code to enable easy initial understanding and debugging), it would render IDEs powerless. If we cram all capabilities an object can offer in a single giant function, later on when trying to utilize that object, IDEs will be of no help. IDEs will only show the existence of one method (which will probably contain a large list of parameters providing values that enforce the branching logic inside that method). So we won’t know how to really use that object unless we open its source code and read its processing logic very carefully. And even then, our heads will probably hurt.&lt;/p&gt;
&lt;p&gt;Another problem with hastily cobbled up, ‘bunched up’ code is that its processing logic is not testable. While we can still write an end-to-end test for that code (input values and the expected output values), we have no way of knowing if the bunched up code is doing any other potentially risky processing. Also, we have no way of testing for edge cases, unusual scenarios, difficult-to-reproduce scenarios etc. That renders our code untestable. Which is a very bad thing to live with.&lt;/p&gt;
&lt;h2&gt;Break up bunched up code by extracting methods&lt;/h2&gt;
&lt;p&gt;Long functions/methods are always a sign of muddled thinking. When a block of code contains numerous statements, it usually means that it is doing way too much processing. Cramming a lot of processing in one place typically means we haven’t carefully thought things through.&lt;/p&gt;
&lt;p&gt;One need not look further than into how companies are typically organized. Instead of having hundreds of employees working in a single department, companies tend to break up into numerous smaller departments. That way, it is much clearer where responsibilities lie.&lt;/p&gt;
&lt;p&gt;Software code is no different. An application exists in order to automate a lot of intricate processing. Processing gets broken into a number of smaller steps, so each step must be mapped onto a separate, isolated block of code. We create such separate, isolated and autonomous block of code by extracting methods. We take a long, bulky block of code and break it up by extracting responsibilities into separate blocks of code.&lt;/p&gt;
&lt;h2&gt;Extracted methods enable better naming&lt;/h2&gt;
&lt;p&gt;Software code is written by developers, but in actuality it is much more often consumed (i.e. read) by developers than it is written.&lt;/p&gt;
&lt;p&gt;When consuming software code, it helps if the code is expressive. Expressiveness boils down to proper structure and proper naming. Consider the following statement:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;if((x &amp;amp;&amp;amp; !y) &amp;amp;&amp;amp; !b) || (b &amp;amp;&amp;amp; y) &amp;amp;&amp;amp; !(z &amp;gt;= 65))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;It would be literally impossible to understand the meaning and the intention of the above statement without actually running the code and stepping through it with a debugger. Such activity is what we call GAK (Geek at Keyboard). It is 100% unproductive, and is quite wasteful.&lt;/p&gt;
&lt;p&gt;Here is where extract method and naming come to the rescue. Take the complex statement contained within the if statement, extract it into its own method, and give that method a meaningful name. For example:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;public bool IsEligible(bool b, bool x, bool y, int z) {&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;code&gt;return ((x &amp;amp;&amp;amp; !y) &amp;amp;&amp;amp; !b) || (b &amp;amp;&amp;amp; y) &amp;amp;&amp;amp; !(z &amp;gt;= 65);&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Now replace the ugly if statement with a more readable statement:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;if(IsEligible(b, x, y, z))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Of course, we should also replace dumb one character variable names with more meaningful names to improve readability.&lt;/p&gt;
&lt;h2&gt;Reuse in legacy code&lt;/h2&gt;
&lt;p&gt;Experience shows that any functionality that is not extracted and properly named and moved to the most reasonable class will never be reused. Extract method fosters frequent reuse, which goes a long way toward improving code quality.&lt;/p&gt;
&lt;h2&gt;Testing the legacy code&lt;/h2&gt;
&lt;p&gt;Writing tests for the existing code is hard and feels less rewarding than doing TDD. Even after we identify that there should be several tests that ensure production code works as expected, when we realize that production code has to be changed to enable testing, we often decide to skip writing tests. Our goals to deliver testable code slowly but surely keep diminishing.&lt;/p&gt;
&lt;p&gt;Writing tests for the legacy code is tedious because it often requires to spend a lot of time and code to set up the preconditions. That’s the opposite of how we write tests when doing TDD, where time spent on writing preconditions is minimal.&lt;/p&gt;
&lt;p&gt;Best way to make legacy code testable is to practice the extract method approach. Locating a block of code nested in loops and conditionals and extracting it will enable us to write small precise tests. Such tests on extracted functions improve not only the testability of the code, but also the understandability. If legacy code now becomes more understandable thanks to extracting methods and writing legible tests, chances of introducing any defects are drastically reduced.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Most of the discussion pertaining to extracting methods would not be necessary when we’re doing TDD. Writing one test first and then making the test pass, then scanning that code for more insights into how the code should be structured and improved, making improvements, and finally making changes part of the code base will guarantee that there will be no need to worry about extracting methods. Since legacy code usually means code that was not crafted following TDD methodology, we are forced to adopt a different approach. In my experience, extract methods gives us the biggest bang for the buck when it comes to modifying legacy code while avoiding risks of breaking the functionality.&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><category term="Posts"></category><category term="Code-quality"></category><category term="legacy-code"></category><category term="extract-method"></category><category term="TDD"></category></entry><entry><title>Benefits of frequent deployments</title><link href="https://wsbctechnicalblog.github.io/benefits-of-frequent-deployments.html" rel="alternate"></link><published>2020-10-15T10:20:00-07:00</published><updated>2020-10-15T10:20:00-07:00</updated><author><name>Alex Bunardzic</name></author><id>tag:wsbctechnicalblog.github.io,2020-10-15:/benefits-of-frequent-deployments.html</id><summary type="html">&lt;p&gt;The longer the wait to deploy, the bigger the risk of things going south&lt;/p&gt;</summary><content type="html">&lt;p&gt;I come from the old school software engineering (started my first programming job back in 1990). Thirty years ago, we were building software the same way we always build high rise buildings. We first obtain the fully fleshed budget and the permission to build. We then wait on the blueprints (requirements) to be signed, sealed and delivered, and then start our ‘brick laying’ work. When we finish building, we ask building inspectors to perform due diligence and confirm if the building is suitable to be put on the market.&lt;/p&gt;
&lt;p&gt;Only after all the above activities get successfully completed do we open up our brand new building. We now let people move in.&lt;/p&gt;
&lt;p&gt;In the world of software engineering, the equivalent of moving in would be the event of deploying our app to production. Naturally, the grand opening can happen only once, after which we move into the ‘keeping the lights on’ phase (i.e. maintenance).&lt;/p&gt;
&lt;p&gt;We call this development model “waterfall” (or, “Big Plan Upfront”).&lt;/p&gt;
&lt;h2&gt;Current situation&lt;/h2&gt;
&lt;p&gt;I’ve tried to plot the workflow that may come close to how we are dealing with the deployment workflow today. We start by pulling a story from our backlog. We estimate the story, schedule it for development, and then develop (implement) it. Once we’re ‘code complete’ we commit the code and push it. We then open a PR and if there are issues/problems, the PR gets rejected and the task of fixing the issue goes back to development.&lt;/p&gt;
&lt;p&gt;Eventually, when the PR gets approved and the branch merged, if there are no issues the merged code (release candidate) goes into UAT. If there are no problems in UAT, release candidate gets deployed to production.&lt;/p&gt;
&lt;p&gt;The real headaches occur when we encounter problems in UAT or in production. These problems must be handled manually (with tedious manual verifications), and the fix to the problem is always very disruptive. To apply the fix, we must stop the server(s) in order to deploy the code. That event destroys all users’ sessions; all user data gets irrevocably lost at that moment. After fixing and re-deploying, we force users to sign in again and start all over, and in general the team goes through a very stressful, even traumatic episode.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Old school deploymeny workflow" src="/images/old-school-deployment.png"&gt;&lt;/p&gt;
&lt;h2&gt;Why high levels of stress?&lt;/h2&gt;
&lt;p&gt;Regardless of the circumstances, it always feels terrible to kick users out of the app while they are in the middle of doing important processing. For that reason, we always prefer to schedule deployments for afterhours. However, that’s often times out of the question because the bug is causing terrible damage to production data and needs to be fixed right away.&lt;/p&gt;
&lt;p&gt;Even if we can afford to wait for the afterhours deployment, it is still stressful because we need to schedule for overtime operations staff to work long hours.&lt;/p&gt;
&lt;h2&gt;What is causing this stressful situation?&lt;/h2&gt;
&lt;p&gt;The reason we find ourselves in an unenviable position of having to fix the defects by harming the end user experience lies in the waterfall model. Unlike the engineering workflow that manages the building of physical objects (such as a high rise building), software is not well suited for the waterfall approach. When building physical objects, it is intuitively obvious that there must be an orderly sequence of events (i.e. impossible to work on building a roof of the house if the foundation and the walls are not finished). When developing software, those concerns are not a constraint.&lt;/p&gt;
&lt;p&gt;Still, the classical engineering mentality tends to get carried over to software engineering. Same as we cannot deliver a partially completed foundation and then deliver partially completed walls etc., the mindset that gets carried over to software engineering insists that all the constituent parts of the solution must be fully fleshed out. That means that rework is not allowed – rework is extremely risky.&lt;/p&gt;
&lt;p&gt;In the world of software development, it is actually advisable to focus on partial delivery. Partial delivery implies rework (if something is partial, that means we need to work some more on it).&lt;/p&gt;
&lt;p&gt;The waterfall workflow denies rework, and is therefore very disturbed if, after delivering a fully fleshed product, something turns out to be defective. This is due to the fact that in the world of waterfall workflow, failure is not an option. Everything must be delivered fully completed on the first try, because there won’t be any second chance (i.e. second chance was not factored in the budget). Therefore, when something malfunctions, all hell breaks loose. It wasn’t part of the original plan!&lt;/p&gt;
&lt;h2&gt;How to remove stress from deployment?&lt;/h2&gt;
&lt;p&gt;In order to minimize and even remove the stress, we must modify the deployment workflow. We must move away from the waterfall model, and into a full blown rework model (where second chances are baked in from the get go).&lt;/p&gt;
&lt;p&gt;Let’s examine an aspirational deployment workflow (something I sketched while wearing my optimistic hat):&lt;/p&gt;
&lt;p&gt;&lt;img alt="Deployment workflow" src="/images/deployment-workflow.png"&gt;&lt;/p&gt;
&lt;p&gt;The process starts from the hypothesis (supplied by the business in the form of a user story). We pull one high priority story from the backlog and slice it vertically. We then work on implementing the vertical slice by doing full blown CI/TDD. If we encounter any problems we go back to the user story and refine it. We do all that work by making sure we perform very frequent commits.&lt;/p&gt;
&lt;p&gt;When done, we push the changed code to the remote repo and open a PR. If there is a problem with our PR (problem detected by automated tests and linters), it’s back to the drawing board. Eventually our PR gets approved and merged. The merge event signals to the team that absolutely all quality checks have been cleared; our code is good to go.&lt;/p&gt;
&lt;p&gt;Next step is to automatically deploy the code to production. Gasp! No, it’s not a typo – we should be free, at any time, to deploy fully tested code to production. However, just because the code is deployed doesn’t automatically mean it is available to end users. We always hide the changes from the users behind feature flags.&lt;/p&gt;
&lt;p&gt;Now that our newly minted code is in production, we engage in monitoring its behaviour. We do it by optimizing system observability (collecting and logging telemetry). The production logs should give us sufficient transparency to know whether the code is a solid release candidate or not.&lt;/p&gt;
&lt;p&gt;If we discover the problem in production (luckily, no skin off anyone’s nose thanks to feature flags), we open a ticket/spec to go back to development. Write more tests, write more imposters, fix the problem and push the fix through the automated gatekeepers.&lt;/p&gt;
&lt;p&gt;Eventually, once the problem is resolved, we release to production. And if despite all precautions we still encounter issues in production, we quickly repeat the automated workflow.&lt;/p&gt;
&lt;p&gt;And because all the fixes to the production bugs are going in via feature flags, there is no need to stop and restart the servers. Also, no user session data gets lost; users merely get rerouted to the new code by flipping the feature flags.&lt;/p&gt;
&lt;h2&gt;Why are frequent deployments so beneficial?&lt;/h2&gt;
&lt;p&gt;Finally, let’s discuss the merits of frequent deployments. Once we remove the stress factor from the deployment process, we should freely engage in deploying as often as possible.&lt;/p&gt;
&lt;p&gt;Why would we want to do that? Frequent deployments teach us invaluable lessons about our market, about our system, about our features. We cannot know whether our changes make sense or not unless we put them out in the field. No focus group can give us accurate prediction on how will a change to the system behave once it goes live.&lt;/p&gt;
&lt;p&gt;As the saying goes, the proof is in the pudding.&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><category term="Posts"></category><category term="TDD"></category><category term="CI"></category></entry><entry><title>Hypothesis-Driven Development</title><link href="https://wsbctechnicalblog.github.io/hypothesis-driven-development.html" rel="alternate"></link><published>2020-10-13T12:20:00-07:00</published><updated>2020-10-13T12:20:00-07:00</updated><author><name>Alex Bunardzic</name></author><id>tag:wsbctechnicalblog.github.io,2020-10-13:/hypothesis-driven-development.html</id><summary type="html">&lt;p&gt;Developing a feature without formulating a hypothesis is like shooting in the dark&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;“The only way it’s all going to go according to plan is if you don’t learn anything.”&lt;/em&gt; -Kent Beck&lt;/p&gt;
&lt;p&gt;Experimentation is the foundation of the scientific method, which is a systematic means of exploring the world around us. But experimentation is not only reserved for the field of scientific research. It has its central place in the world of business too.&lt;/p&gt;
&lt;p&gt;Most of us are by now familiar with the business methodology called Minimum Viable Product (&lt;strong&gt;MVP&lt;/strong&gt;). This Minimum Viable Product is basically just an experiment. By building and launching MVPs, business operations are engaging in a systematic means of exploring the markets.&lt;/p&gt;
&lt;p&gt;If we look at market leaders today, we learn that they’re not doing projects anymore. The only thing they’re doing is experiments. &lt;strong&gt;Customer discover&lt;/strong&gt;y&lt;strong&gt; and &lt;/strong&gt;Lean strategies&lt;strong&gt; are used to test assumptions about the markets. Such approach is equivalent to Test-Driven Development (&lt;/strong&gt;TDD**), which is the process we are intimately familiar with. In TDD, we write the hypothesis first (the test). We then use that test to guide our implementation. Ultimately, product or service development is no different than TDD – we first write a hypothesis, that hypothesis guides our implementation which serves as measurable validation of the hypothesis.&lt;/p&gt;
&lt;h2&gt;Information discovery&lt;/h2&gt;
&lt;p&gt;Back in the pre-agile days, requirements gathering was an important activity that used to always kick-off the project. A bunch of SMEs used to get assigned on the project, and were tasked with gathering the requirements. After a prolonged period of upfront information discovery, the gathered requirements got reviewed and, if agreed upon, signed off and frozen. No more changes allowed!&lt;/p&gt;
&lt;p&gt;Back then it seemed a perfectly reasonable thing to do. The fly in the ointment always kicked in once the build phase commenced. Sooner or later, as the project progresses, new information comes into the light of day. Suddenly, what we initially held as incontrovertible truth, gets challenged by the newly acquired information and evidence.&lt;/p&gt;
&lt;p&gt;But the clincher was in the gated phases. Remember, once requirements get signed off, they get frozen. No more changes, no scope creep allowed. Which means, newly obtained market insights get willfully ignored.&lt;/p&gt;
&lt;p&gt;Well, that’s kind of a foolish neglect. More often than not, the newly emerging evidence could be of critical importance to the health of the business operation. Can we afford to ignore it? You be we cannot! We have no recourse other than to embrace the change.&lt;/p&gt;
&lt;p&gt;It is after a number of prominent fiascos in the industry that many software development projects switched to the agile approach. With agile, information discovery is partial. With agile we never claim that we have gathered the requirements, and are now ready to implement them. We keep discovering information and implementing it at the same time (we embrace the change). We do it in tiny steps, keeping our efforts interruptible and steerable at all times.&lt;/p&gt;
&lt;p&gt;How to leverage the scientific method&lt;/p&gt;
&lt;p&gt;Scientific method is empirical and consists of performing the following steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Step 1: make and record careful observations&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 2: perform orientation with regards to observed evidence&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 3: formulate a hypothesis, including measurable indicators for hypothesis evaluation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 4: design an experiment that will enable us to test the hypothesis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 5: conduct the experiment (i.e. release the partial implementation)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 6: collect the telemetry that results from running the experiment&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 7: evaluate the results of the experiment&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 8: accept or reject the hypothesis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 9: go to Step 1&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;How to formulate a hypothesis&lt;/h2&gt;
&lt;p&gt;When switching from projects to experiments, traditional user story framework (As a/I want to/So that) is proving insufficient. The traditional user story format does not expose the signals needed in order to evaluate the outcomes. Instead, old school user story format is focused on outputs.&lt;/p&gt;
&lt;p&gt;The problem with doing an experiment without first formulating a hypothesis is that there is a danger of introducing a bias when interpreting the results of an experiment. Defining the measurable signals that will enable us to corroborate our hypothesis must be done before we conduct the experiment. That way, we can remain completely impartial when interpreting the results of the experiment. We cannot be swayed by wishful thinking.&lt;/p&gt;
&lt;p&gt;The best way to proceed with formulating a hypothesis is to use the following format:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We believe&lt;/strong&gt; [this capability]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Will result in&lt;/strong&gt; [this outcome]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We will have the confidence to proceed when&lt;/strong&gt; [we see a measurable signal]&lt;/p&gt;
&lt;h2&gt;Working software is not a measure of progress&lt;/h2&gt;
&lt;p&gt;Output-based metrics and concepts (Definition of Done, acceptance criteria, burndown charts, and velocity) are good for detecting working software, but fall miserably when it comes to detecting if working software adds value.&lt;/p&gt;
&lt;p&gt;“Done” only matters if it adds value. Working software that doesn’t add value cannot be declared “done”.&lt;/p&gt;
&lt;h2&gt;The forgotten column&lt;/h2&gt;
&lt;p&gt;Technology-centric projects break activities down into four columns:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Backlog of ideas&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Analysis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In progress&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shipped&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The above structure is based on the strong belief that all software that works is valuable. That focus must now shift toward continuously delivering real value, something that serves customers. Agilists value outcomes (value to the customers) over features.&lt;/p&gt;
&lt;p&gt;The new breakdown for hypothesis-driven development looks something like this:&lt;/p&gt;
&lt;table&gt;
&lt;tr&gt;
  &lt;th&gt;
    &lt;td&gt;&lt;strong&gt;Ideas backlog&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt;&lt;strong&gt;Analysis&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt;&lt;strong&gt;In progress&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt;&lt;strong&gt;Shipped&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt;&lt;strong&gt;Achieved desired outcome&lt;/strong&gt;&lt;/td&gt;
  &lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
  &lt;td&gt;Hypothesis 11&lt;/td&gt;&lt;td&gt;Hypothesis 20&lt;/td&gt;&lt;td&gt;Hypothesis 26&lt;/td&gt;&lt;td&gt;Hypothesis 1&lt;/td&gt;&lt;td&gt;Hypothesis 1&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
  &lt;td&gt;Hypothesis 12&lt;/td&gt;&lt;td&gt;Hypothesis 21&lt;/td&gt;&lt;td&gt;Hypothesis 5&lt;/td&gt;&lt;td&gt;Hypothesis 5&lt;/td&gt;&lt;td&gt;Hypothesis 5&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
  &lt;td&gt;Hypothesis 13&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;Hypothesis 10&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
  &lt;td&gt;Hypothesis 14&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
  &lt;td&gt;Hypothesis 15&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
  &lt;td&gt;Hypothesis 16&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
  &lt;td&gt;Hypothesis 17&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
  &lt;td&gt;Hypothesis 18&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
  &lt;td&gt;Hypothesis 19&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;All eyes must remain peeled on the &lt;strong&gt;Achieved desired outcome&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><category term="Posts"></category><category term="TDD"></category><category term="CI"></category></entry><entry><title>The cost of avoiding change</title><link href="https://wsbctechnicalblog.github.io/the-cost-of-avoiding-change.html" rel="alternate"></link><published>2020-10-03T10:20:00-07:00</published><updated>2020-10-03T10:20:00-07:00</updated><author><name>Alex Bunardzic</name></author><id>tag:wsbctechnicalblog.github.io,2020-10-03:/the-cost-of-avoiding-change.html</id><summary type="html">&lt;p&gt;Change is stressful and risky, but avoing it is even riskier&lt;/p&gt;</summary><content type="html">&lt;p&gt;Software engineers are notorious for being averse to change. We prefer the steady state, stability. The reason we prefer steady state lies in the fact that systems we are building tend to be complex. Complexity breeds brittleness, and so we are keen on doing everything possible to avoid building brittle systems. Who could blame us?&lt;/p&gt;
&lt;h2&gt;City on the Hill&lt;/h2&gt;
&lt;p&gt;When engineering a system, we tend to think about it in terms of an endpoint (let’s call that endpoint City on the Hill). This idealized city needs to be defined rigorously. After all, that’s what engineering is all about – rigor.&lt;/p&gt;
&lt;p&gt;After we’ve defined it, we optimize the process of building it offline. Once it’s built, we confirm that it’s done (using our Definition of Done yardstick). We then push it online, move into it, and never change it again (if we need to make any changes, we’d be admitting that we haven’t defined it rigorously to begin with).&lt;/p&gt;
&lt;h2&gt;Efficiency&lt;/h2&gt;
&lt;p&gt;The central idea of efficiency is that changing something is a waste. Why did we build the thing in the first place if we are to turn around and change it? Wouldn’t doing that mean that we didn’t actually know how to build our City on the Hill? Why not build our system correctly to begin with? Anything else would be grossly inefficient.&lt;/p&gt;
&lt;h2&gt;Change is bad&lt;/h2&gt;
&lt;p&gt;According to the above reasoning, change is bad. It is wasteful and inefficient. Pushed to its limit, this ‘change is bad’ sentiment blossoms into full-blown ‘change is to be feared’ mindset.&lt;/p&gt;
&lt;p&gt;Our City on the Hill ideal implies finality. Upon reaching our final destination, the reason to ever consider change is only if we realize that we have hit the wrong target. And that means utmost defeat (the ultimate inefficiency and waste).&lt;/p&gt;
&lt;h2&gt;All complexity at the beginning and all reward at the end&lt;/h2&gt;
&lt;p&gt;The City on the Hill approach to software engineering makes our profession extremely hard. We frontload all the complexity at the very beginning of the project. We ‘kitchen sink’ the project: since we only get one shot to make it right, we’d better create a laundry list of all the features we will ever need.&lt;/p&gt;
&lt;p&gt;Working on the detailed laundry list of all the features is a complex process. And it does not deliver any rewards. It may take days, weeks, even months to get to the end of job. And once we get there, we reap no rewards. All we have to show for is a pile of documents and diagrams – zero shippable software. The work on building shippable software has yet to commence. And it is only at the very end, once we ship the finished City on the Hill product, that we get any rewards for this gargantuan effort.&lt;/p&gt;
&lt;h2&gt;Gold-plating the parts&lt;/h2&gt;
&lt;p&gt;The pressure of having only one shot at building our City on the Hill forces us to gold-plate all parts we’re building. We feel compelled to make each part better than it has to be in order to do its job. We are at that point playing the prediction game – maybe in the future this function will have to be integrated with another system, and because we won’t be making any changes to it later on, let’s make sure now it is sufficiently generalized. Or, add those bells and whistles that only one in thousand users ever notices, let alone makes any use of it.&lt;/p&gt;
&lt;h2&gt;Fear of imperfections&lt;/h2&gt;
&lt;p&gt;The ‘kitchen sink’ laundry list of features, where each part must be gold-plated, results in code that is far more complex than it needs to be. That naturally leads to lack of understanding. Lack of understanding leads to lack of confidence. That lack of confidence makes development slower because of the looming finality – do it once and make sure you do it right!&lt;/p&gt;
&lt;p&gt;Such attitude results in the fear of imperfection. The fear of being wrong tends to lead to paralysis. Suddenly, the stakes of any decision made by the engineers seem incredibly high. Trying things and experimenting is viewed as wasting precious time and resources.&lt;/p&gt;
&lt;h2&gt;Death march&lt;/h2&gt;
&lt;p&gt;The finality of the City on the Hill approach leads to very late validation. By the time we catch any issues with our gold-plated parts and how they struggle to integrate, the goodwill has already been largely spent. All the hard work invested in taming considerable complexities rarely pays off if we adopt the ‘failure is not an option’ mentality.&lt;/p&gt;
&lt;p&gt;We cannot confirm whether the code we’re building actually implements our City until all pieces are in. Five-to-midnight is the worst time to discover we have problems. That is the point of maximum stress, as we are on the collision course to our deadline.&lt;/p&gt;
&lt;h2&gt;Break the workload into parallel chunks?&lt;/h2&gt;
&lt;p&gt;To avoid the looming death march described above, we often see workload being divided into independent chunks to be worked on in parallel. Sounds reasonable on the surface, until we take a closer look and factor-in the cost of control needed to coordinate and synchronize independent strains of work. Managing that kind of parallelism is a tall order. Out of sheer necessity, management introduces ‘wait states’ and ‘sync points’. The independent development suddenly ceases to be independent, as it must become strictly lockstep. Copious documents, emails, tickets and handoffs start proliferating, slowing everything down to a crawl.&lt;/p&gt;
&lt;h2&gt;Rework Avoidance&lt;/h2&gt;
&lt;p&gt;Avoiding change leads to avoiding rework. Any attempt at making something must be done in such a way that there would never be any need for rework. Make it right from the get go, on the first attempt.&lt;/p&gt;
&lt;p&gt;The cost of avoiding rework is best expressed in the cost of late failures. Those dreadful five-to-midnight failures are extremely costly; not only that, but they leave very little room for rework. By the time we realize that things are not gelling as expected, it is often too late for attempting any rework.&lt;/p&gt;
&lt;h2&gt;Switch to partial delivery&lt;/h2&gt;
&lt;p&gt;In order to evade the exorbitant cost of rework avoidance, we must pivot and embrace change via partial delivery. Embracing change necessitates innovation, experimenting, trying things out. The only way to do that effectively is to cultivate the ‘fail early’ mindset. Failure is desirable because it prompts us to fix it while it is still easy to do so.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Avoiding change, while very tempting and perfectly natural, usually ends up being very costly. Fear of failure is preventing innovation and experimentation by stifling change. The only way to avoid paying such exorbitant price is to embrace the change, embrace failure, but do it in an incremental fashion. Small steps, each one focused on partial delivery. That way, success is assured.&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><category term="Posts"></category><category term="TDD"></category><category term="CI"></category></entry><entry><title>How does it feel to write software when doing TDD?</title><link href="https://wsbctechnicalblog.github.io/how-does-it-feel-to-tdd.html" rel="alternate"></link><published>2020-09-17T22:21:00-07:00</published><updated>2020-09-17T22:21:00-07:00</updated><author><name>Alex Bunardzic</name></author><id>tag:wsbctechnicalblog.github.io,2020-09-17:/how-does-it-feel-to-tdd.html</id><summary type="html">&lt;p&gt;Any discipline requires serious investment in time&lt;/p&gt;</summary><content type="html">&lt;p&gt;TDD is a very strict discipline. As with any other discipline, in the beginning it always feels extremely restricting and counter-productive. And as with any other discipline, if you persevere and stick to it, the initial awkwardness and confusion fades away and the benefits of the discipline start bearing fruit.&lt;/p&gt;
&lt;p&gt;It’s the same as with training for a marathon, for example. At first, you cannot run longer distances without hurting and losing your breath. But little by little, if you keep doing your modest exercises every day, you discover that you can run longer and longer distances without losing your breath and without hurting. Before you know it, you find yourself in a situation where you can run tens of kilometres without feeling any discomfort.&lt;/p&gt;
&lt;p&gt;TDD is no different. It feels weird at first. Since software development is all about speed (deliver value as soon as possible), doing TDD feels absolutely idiotic in the beginning. Most of us who were trying to learn how to do TDD initially felt that time spent doing TDD would be much, much better spent writing code. It just did not make any sense to waste precious time on writing tests first.&lt;/p&gt;
&lt;p&gt;It is in a way similar to how surgeons in the past felt about washing their hands. They were often in a critical situation where patients were in a life threatening state on the operating table, and instead of jumping in and operating on them, they were required to stop and first wash their hands. Their unanimous reaction to that discipline was “Hold on. You can’t be serious?”&lt;/p&gt;
&lt;p&gt;Later on, when science discovered microorganisms, everything became much clearer, and the need to wash hands before doing the surgery became obvious.&lt;/p&gt;
&lt;p&gt;TDD is still tricky, because we haven’t discovered those ‘microorganisms’ in software which will mandate that we do TDD before writing code.&lt;/p&gt;
&lt;p&gt;Another real life example I could offer from personal experience is learning to play the guitar. When I was young I wanted to learn how to play the guitar as fast as those guitar superheros. Naturally, all I was doing while practising guitar is play as fast as I can. With terrible results. My playing sounded stifled, erratic, uneven and forced. Instead of being able to play fast, I played as if I was hyperventilating.&lt;/p&gt;
&lt;p&gt;Then I discovered the merit of another discipline — practising really, really slow. It defies logic, and is on the surface counter-intuitive, but it is absolutely true that if your goal is to play guitar very fast, the quickest way to get there is by practising really slow. And by really slow I mean painstakingly slow. Like, idiotically slow. But if you stick to it, it is guaranteed to get you to the point where you are able to play the guitar at blinding speeds.&lt;/p&gt;
&lt;p&gt;Same applies to software engineering/development. If you want to deliver software at blinding speeds, the most efficient way to do it is by slowing down and embracing TDD. There isn’t any other discipline in software development that delivers results quicker than TDD. And I’ve tried everything in my 30+ years career as software engineer. Nothing beats TDD.&lt;/p&gt;
&lt;p&gt;Of course, if people, upon reading this, give TDD a shot and spend a few hours doing it, they will no doubt find out that spectacular results are not forthcoming. Similarly, if a budding guitar player spends a few hours practising real slow, he or she will get disappointed — those few hours of practice didn’t bear any desired fruits.&lt;/p&gt;
&lt;p&gt;No worthy result comes overnight. You get out of it what you put into it. You need some serious woodshedding spent on TDD before you start seeing the results. But the effort and the wait are well worth it. Only those who are prepared to invest months and months of focused, dedicated woodshedding in TDD will arrive at the stage when they start reaping the huge benefits of TDD.&lt;/p&gt;
&lt;p&gt;Once you get there, you realize you are at a much higher level of mastery than your colleagues who remain clueless about the benefits of TDD. Ordinary, base software developers who only waste time on writing the shipping code actually spend inordinate amount of time on activities that have nothing to do with writing the lines of shipping code. They do a lot of manual testing, spending hours on varying the configuration and the environmental variables in order to convince themselves that the code they wrote actually works. If we were to average the hours they spend on manually wrangling configuration/test data vs time they spend actually writing code, we will see that the time spent writing code is usually less than 10%. Not very productive, no matter how we look at it.&lt;/p&gt;
&lt;p&gt;None of those copious non-productive hours get spent by engineers who have mastered TDD. And that is the reason TDD feels so great — it gives you wings and superpowers that by far exceed anything your talented and amazing non-TDD peers could ever do.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><category term="Posts"></category><category term="TDD"></category></entry><entry><title>Feature-flag Driven Development (FFDD)</title><link href="https://wsbctechnicalblog.github.io/feature-flag-driven-development.html" rel="alternate"></link><published>2020-09-04T11:10:00-07:00</published><updated>2020-09-04T11:10:00-07:00</updated><author><name>Alex Bunardzic</name></author><id>tag:wsbctechnicalblog.github.io,2020-09-04:/feature-flag-driven-development.html</id><summary type="html">&lt;p&gt;Replace physical modularity with logical modularity&lt;/p&gt;</summary><content type="html">&lt;p&gt;Experts say that repo branching workflow is poor man’s modularization (by experts I mostly refer to Martin Fowler and his team of deep thinkers). What do we mean by branching being poor man’s modularization?&lt;/p&gt;
&lt;h2&gt;Well modularized repo&lt;/h2&gt;
&lt;p&gt;Let’s examine how change management propagates in a repo that has been properly modularized from the get go:&lt;/p&gt;
&lt;p&gt;A new feature needs to be added to the product, which necessitates change to the codebase. Because the code is fully modularized, it is closed to any changes related to the new feature, but is at the same time open for any changes that would extend its feature set (the Open/Closed Principle, part of the SOLID package).&lt;/p&gt;
&lt;p&gt;The new feature will thus be coded by adding brand new modules. Barely any line of existing code will have to be modified, since the new feature would be a plugin.&lt;/p&gt;
&lt;h2&gt;Poorly modularized repo&lt;/h2&gt;
&lt;p&gt;A code that is poorly modularized will have to be modified (sometimes heavily) in order to introduce a new feature into the product.&lt;/p&gt;
&lt;p&gt;Any time two or more people are working on the same block of code, they introduce a moving target. Changes made to the same codebase may result in a conflict. That conflict potentially arises at the time when we are trying to retrofit new code into the existing codebase. Those are the dreaded merge conflicts.&lt;/p&gt;
&lt;h2&gt;Why do we branch in the first place?&lt;/h2&gt;
&lt;p&gt;The main reason we copy the existing code base and turn it into a feature branch is to protect the healthy master branch from getting corrupted. Teamwork often necessitates that two or more feature branches get created during sprint, and that means that there is an ongoing work that is happening in parallel. When the time comes to bring the new changes to the healthy branch, some of those new changes may mutually collide.&lt;/p&gt;
&lt;p&gt;So the caution we exercise by branching is introducing unwanted risks of creating merge conflicts.&lt;/p&gt;
&lt;h2&gt;How to avoid merge conflicts?&lt;/h2&gt;
&lt;p&gt;During the workflow described above, it is not really possible to avoid potential merge conflicts. But we can certainly minimize potential conflicts.&lt;/p&gt;
&lt;p&gt;It all boils down to timing. When we take a copy of the healthy branch and go away and begin making changes to the code, the clock starts ticking. The longer we wait to bring our changes to the healthy branch, the greater that chances that someone else had already made changes to it that may collide with our changes.&lt;/p&gt;
&lt;p&gt;That is one of the main reasons why best practices advocate short-lived branches. The shorter the lifespan of a branch, the smaller the risk of having merge conflicts. And lesser merge conflicts mean quicker value delivery and lesser churn.&lt;/p&gt;
&lt;p&gt;And of course, merge conflicts are of much lower possibility in well modularized codebases, as we have already discussed above.&lt;/p&gt;
&lt;h2&gt;Feature flags&lt;/h2&gt;
&lt;p&gt;Much as Martin Fowler et al claim that branching is poor man’s modularization, it is also possible to say that branching is poor man’s feature flags. So what are feature flags?&lt;/p&gt;
&lt;p&gt;Feature flags could be viewed as logical branching. While physical branches, as they are practiced in modern engineering mostly using git, require making a physical copy of the repo and giving it a unique name, feature flags could be used without necessarily having to make a physical copy. When using Feature-Flag Driven Development (FFDD), we simply leave the existing code intact and write new modules that get conditionally called. The conditional logic is binary, and is governed by the feature flag (which could be either in on or in off state). If the flag is in the on state, the new code will get executed. Otherwise, execution continues as usual (old code runs).&lt;/p&gt;
&lt;p&gt;FFDD enables us to add potentially risky changes to the healthy codebase, without going through the song and dance of trying to merge the changes and risking merge conflicts. This technique then enables us to quickly ship new features in stealth mode. Our regular customer population will not get affected, since they will still be using the old, tested codebase. But our QA can then safely assess and evaluate the risks and potential merits of the new code. That activity would be the equivalent of the Pull Request in the branch-driven development discipline. If the PR of the code under the feature flag passes the muster, the old code gets decommissioned and the new code becomes the healthy version of the codebase.&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;</content><category term="Posts"></category><category term="Feature-flag"></category></entry></feed>