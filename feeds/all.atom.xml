<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>WorkSafeBC Tech Blog</title><link href="https://wsbctechnicalblog.github.io/" rel="alternate"></link><link href="https://wsbctechnicalblog.github.io/feeds/all.atom.xml" rel="self"></link><id>https://wsbctechnicalblog.github.io/</id><updated>2020-10-13T12:20:00-07:00</updated><entry><title>Hypothesis-Driven Development</title><link href="https://wsbctechnicalblog.github.io/hypothesis-driven-development.html" rel="alternate"></link><published>2020-10-13T12:20:00-07:00</published><updated>2020-10-13T12:20:00-07:00</updated><author><name>Alex Bunardzic</name></author><id>tag:wsbctechnicalblog.github.io,2020-10-13:/hypothesis-driven-development.html</id><summary type="html">&lt;p&gt;Developing a feature without formulating a hypothesis is like shooting in the dark&lt;/p&gt;</summary><content type="html">&lt;p&gt;“The only way it’s all going to go according to plan is if you don’t learn anything.” -Kent Beck&lt;/p&gt;
&lt;p&gt;Experimentation is the foundation of the scientific method, which is a systematic means of exploring the world around us. But experimentation is not only reserved for the field of scientific research. It has its central place in the world of business too.&lt;/p&gt;
&lt;p&gt;Most of us are by now familiar with the business methodology called Minimum Viable Product (&lt;strong&gt;MVP&lt;/strong&gt;). This Minimum Viable Product is basically just an experiment. By building and launching MVPs, business operations are engaging in a systematic means of exploring the markets.&lt;/p&gt;
&lt;p&gt;If we look at market leaders today, we learn that they’re not doing projects anymore. The only thing they’re doing is experiments. &lt;strong&gt;Customer discover&lt;/strong&gt;y&lt;strong&gt; and &lt;/strong&gt;Lean strategies&lt;strong&gt; are used to test assumptions about the markets. Such approach is equivalent to Test-Driven Development (&lt;/strong&gt;TDD**), which is the process we are intimately familiar with. In TDD, we write the hypothesis first (the test). We then use that test to guide our implementation. Ultimately, product or service development is no different than TDD – we first write a hypothesis, that hypothesis guides our implementation which serves as measurable validation of the hypothesis.&lt;/p&gt;
&lt;h2&gt;Information discovery&lt;/h2&gt;
&lt;p&gt;Back in the pre-agile days, requirements gathering was an important activity that used to always kick-off the project. A bunch of SMEs used to get assigned on the project, and were tasked with gathering the requirements. After a prolonged period of upfront information discovery, the gathered requirements got reviewed and, if agreed upon, signed off and frozen. No more changes allowed!&lt;/p&gt;
&lt;p&gt;Back then it seemed a perfectly reasonable thing to do. The fly in the ointment always kicked in once the build phase commenced. Sooner or later, as the project progresses, new information comes into the light of day. Suddenly, what we initially held as incontrovertible truth, gets challenged by the newly acquired information and evidence.&lt;/p&gt;
&lt;p&gt;But the clincher was in the gated phases. Remember, once requirements get signed off, they get frozen. No more changes, no scope creep allowed. Which means, newly obtained market insights get willfully ignored.&lt;/p&gt;
&lt;p&gt;Well, that’s kind of a foolish neglect. More often than not, the newly emerging evidence could be of critical importance to the health of the business operation. Can we afford to ignore it? You be we cannot! We have no recourse other than to embrace the change.&lt;/p&gt;
&lt;p&gt;It is after a number of prominent fiascos in the industry that many software development projects switched to the agile approach. With agile, information discovery is partial. With agile we never claim that we have gathered the requirements, and are now ready to implement them. We keep discovering information and implementing it at the same time (we embrace the change). We do it in tiny steps, keeping our efforts interruptible and steerable at all times.&lt;/p&gt;
&lt;p&gt;How to leverage the scientific method&lt;/p&gt;
&lt;p&gt;Scientific method is empirical and consists of performing the following steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Step 1: make and record careful observations&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 2: perform orientation with regards to observed evidence&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 3: formulate a hypothesis, including measurable indicators for hypothesis evaluation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 4: design an experiment that will enable us to test the hypothesis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 5: conduct the experiment (i.e. release the partial implementation)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 6: collect the telemetry that results from running the experiment&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 7: evaluate the results of the experiment&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 8: accept or reject the hypothesis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 9: go to Step 1&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;How to formulate a hypothesis&lt;/h2&gt;
&lt;p&gt;When switching from projects to experiments, traditional user story framework (As a/I want to/So that) is proving insufficient. The traditional user story format does not expose the signals needed in order to evaluate the outcomes. Instead, old school user story format is focused on outputs.&lt;/p&gt;
&lt;p&gt;The problem with doing an experiment without first formulating a hypothesis is that there is a danger of introducing a bias when interpreting the results of an experiment. Defining the measurable signals that will enable us to corroborate our hypothesis must be done before we conduct the experiment. That way, we can remain completely impartial when interpreting the results of the experiment. We cannot be swayed by wishful thinking.&lt;/p&gt;
&lt;p&gt;The best way to proceed with formulating a hypothesis is to use the following format:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We believe&lt;/strong&gt; [this capability]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Will result in&lt;/strong&gt; [this outcome]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We will have the confidence to proceed when&lt;/strong&gt; [we see a measurable signal]&lt;/p&gt;
&lt;h2&gt;Working software is not a measure of progress&lt;/h2&gt;
&lt;p&gt;Output-based metrics and concepts (Definition of Done, acceptance criteria, burndown charts, and velocity) are good for detecting working software, but fall miserably when it comes to detecting if working software adds value.&lt;/p&gt;
&lt;p&gt;“Done” only matters if it adds value. Working software that doesn’t add value cannot be declared “done”.&lt;/p&gt;
&lt;h2&gt;The forgotten column&lt;/h2&gt;
&lt;p&gt;Technology-centric projects break activities down into four columns:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Backlog of ideas&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Analysis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In progress&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shipped&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The above structure is based on the strong belief that all software that works is valuable. That focus must now shift toward continuously delivering real value, something that serves customers. Agilists value outcomes (value to the customers) over features.&lt;/p&gt;
&lt;p&gt;The new breakdown for hypothesis-driven development looks something like this:&lt;/p&gt;
&lt;p&gt;| &lt;strong&gt;Ideas backlog&lt;/strong&gt; | &lt;strong&gt;Analysis&lt;/strong&gt;               | &lt;strong&gt;In progress&lt;/strong&gt;   | &lt;strong&gt;Shipped&lt;/strong&gt;       | &lt;strong&gt;Achieved desired outcome&lt;/strong&gt; |&lt;/p&gt;
&lt;p&gt;|---------------|------------------------|---------------|---------------|--------------------------|&lt;/p&gt;
&lt;p&gt;| Hypothesis 11 | Hypothesis 20          | Hypothesis 26 | Hypothesis 2  | Hypothesis 1 |&lt;/p&gt;
&lt;p&gt;| Hypothesis 12 | Hypothesis 21          |               | Hypothesis 5  | Hypothesis 5 |&lt;/p&gt;
&lt;p&gt;| Hypothesis 13 |                        |               | Hypothesis 10 |&lt;/p&gt;
&lt;p&gt;| Hypothesis 14 |&amp;nbsp;|&amp;nbsp;|&amp;nbsp;|&amp;nbsp;|&lt;/p&gt;
&lt;p&gt;| Hypothesis 15 |&amp;nbsp;|&amp;nbsp;|&amp;nbsp;|&amp;nbsp;|&lt;/p&gt;
&lt;p&gt;| Hypothesis 16 |&amp;nbsp;|&amp;nbsp;|&amp;nbsp;|&amp;nbsp;|&lt;/p&gt;
&lt;p&gt;| Hypothesis 17 |&amp;nbsp;|&amp;nbsp;|&amp;nbsp;|&amp;nbsp;|&lt;/p&gt;
&lt;p&gt;| Hypothesis 18 |&amp;nbsp;|&amp;nbsp;|&amp;nbsp;|&amp;nbsp;|&lt;/p&gt;
&lt;p&gt;| Hypothesis 19 |&amp;nbsp;|&amp;nbsp;|&amp;nbsp;|&amp;nbsp;|&lt;/p&gt;
&lt;p&gt;All eyes must remain peeled on the &lt;strong&gt;Achieved desired outcome&lt;/strong&gt;.&lt;/p&gt;</content><category term="Software, Change, Hypothesis"></category><category term="TDD"></category><category term="CI"></category></entry><entry><title>The cost of avoiding change</title><link href="https://wsbctechnicalblog.github.io/the-cost-of-avoiding-change.html" rel="alternate"></link><published>2020-10-03T10:20:00-07:00</published><updated>2020-10-03T10:20:00-07:00</updated><author><name>Alex Bunardzic</name></author><id>tag:wsbctechnicalblog.github.io,2020-10-03:/the-cost-of-avoiding-change.html</id><summary type="html">&lt;p&gt;Change is stressful and risky, but avoing it is even riskier&lt;/p&gt;</summary><content type="html">&lt;p&gt;Software engineers are notorious for being averse to change. We prefer the steady state, stability. The reason we prefer steady state lies in the fact that systems we are building tend to be complex. Complexity breeds brittleness, and so we are keen on doing everything possible to avoid building brittle systems. Who could blame us?&lt;/p&gt;
&lt;h2&gt;City on the Hill&lt;/h2&gt;
&lt;p&gt;When engineering a system, we tend to think about it in terms of an endpoint (let’s call that endpoint City on the Hill). This idealized city needs to be defined rigorously. After all, that’s what engineering is all about – rigor.&lt;/p&gt;
&lt;p&gt;After we’ve defined it, we optimize the process of building it offline. Once it’s built, we confirm that it’s done (using our Definition of Done yardstick). We then push it online, move into it, and never change it again (if we need to make any changes, we’d be admitting that we haven’t defined it rigorously to begin with).&lt;/p&gt;
&lt;h2&gt;Efficiency&lt;/h2&gt;
&lt;p&gt;The central idea of efficiency is that changing something is a waste. Why did we build the thing in the first place if we are to turn around and change it? Wouldn’t doing that mean that we didn’t actually know how to build our City on the Hill? Why not build our system correctly to begin with? Anything else would be grossly inefficient.&lt;/p&gt;
&lt;h2&gt;Change is bad&lt;/h2&gt;
&lt;p&gt;According to the above reasoning, change is bad. It is wasteful and inefficient. Pushed to its limit, this ‘change is bad’ sentiment blossoms into full-blown ‘change is to be feared’ mindset.&lt;/p&gt;
&lt;p&gt;Our City on the Hill ideal implies finality. Upon reaching our final destination, the reason to ever consider change is only if we realize that we have hit the wrong target. And that means utmost defeat (the ultimate inefficiency and waste).&lt;/p&gt;
&lt;h2&gt;All complexity at the beginning and all reward at the end&lt;/h2&gt;
&lt;p&gt;The City on the Hill approach to software engineering makes our profession extremely hard. We frontload all the complexity at the very beginning of the project. We ‘kitchen sink’ the project: since we only get one shot to make it right, we’d better create a laundry list of all the features we will ever need.&lt;/p&gt;
&lt;p&gt;Working on the detailed laundry list of all the features is a complex process. And it does not deliver any rewards. It may take days, weeks, even months to get to the end of job. And once we get there, we reap no rewards. All we have to show for is a pile of documents and diagrams – zero shippable software. The work on building shippable software has yet to commence. And it is only at the very end, once we ship the finished City on the Hill product, that we get any rewards for this gargantuan effort.&lt;/p&gt;
&lt;h2&gt;Gold-plating the parts&lt;/h2&gt;
&lt;p&gt;The pressure of having only one shot at building our City on the Hill forces us to gold-plate all parts we’re building. We feel compelled to make each part better than it has to be in order to do its job. We are at that point playing the prediction game – maybe in the future this function will have to be integrated with another system, and because we won’t be making any changes to it later on, let’s make sure now it is sufficiently generalized. Or, add those bells and whistles that only one in thousand users ever notices, let alone makes any use of it.&lt;/p&gt;
&lt;h2&gt;Fear of imperfections&lt;/h2&gt;
&lt;p&gt;The ‘kitchen sink’ laundry list of features, where each part must be gold-plated, results in code that is far more complex than it needs to be. That naturally leads to lack of understanding. Lack of understanding leads to lack of confidence. That lack of confidence makes development slower because of the looming finality – do it once and make sure you do it right!&lt;/p&gt;
&lt;p&gt;Such attitude results in the fear of imperfection. The fear of being wrong tends to lead to paralysis. Suddenly, the stakes of any decision made by the engineers seem incredibly high. Trying things and experimenting is viewed as wasting precious time and resources.&lt;/p&gt;
&lt;h2&gt;Death march&lt;/h2&gt;
&lt;p&gt;The finality of the City on the Hill approach leads to very late validation. By the time we catch any issues with our gold-plated parts and how they struggle to integrate, the goodwill has already been largely spent. All the hard work invested in taming considerable complexities rarely pays off if we adopt the ‘failure is not an option’ mentality.&lt;/p&gt;
&lt;p&gt;We cannot confirm whether the code we’re building actually implements our City until all pieces are in. Five-to-midnight is the worst time to discover we have problems. That is the point of maximum stress, as we are on the collision course to our deadline.&lt;/p&gt;
&lt;h2&gt;Break the workload into parallel chunks?&lt;/h2&gt;
&lt;p&gt;To avoid the looming death march described above, we often see workload being divided into independent chunks to be worked on in parallel. Sounds reasonable on the surface, until we take a closer look and factor-in the cost of control needed to coordinate and synchronize independent strains of work. Managing that kind of parallelism is a tall order. Out of sheer necessity, management introduces ‘wait states’ and ‘sync points’. The independent development suddenly ceases to be independent, as it must become strictly lockstep. Copious documents, emails, tickets and handoffs start proliferating, slowing everything down to a crawl.&lt;/p&gt;
&lt;h2&gt;Rework Avoidance&lt;/h2&gt;
&lt;p&gt;Avoiding change leads to avoiding rework. Any attempt at making something must be done in such a way that there would never be any need for rework. Make it right from the get go, on the first attempt.&lt;/p&gt;
&lt;p&gt;The cost of avoiding rework is best expressed in the cost of late failures. Those dreadful five-to-midnight failures are extremely costly; not only that, but they leave very little room for rework. By the time we realize that things are not gelling as expected, it is often too late for attempting any rework.&lt;/p&gt;
&lt;h2&gt;Switch to partial delivery&lt;/h2&gt;
&lt;p&gt;In order to evade the exorbitant cost of rework avoidance, we must pivot and embrace change via partial delivery. Embracing change necessitates innovation, experimenting, trying things out. The only way to do that effectively is to cultivate the ‘fail early’ mindset. Failure is desirable because it prompts us to fix it while it is still easy to do so.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Avoiding change, while very tempting and perfectly natural, usually ends up being very costly. Fear of failure is preventing innovation and experimentation by stifling change. The only way to avoid paying such exorbitant price is to embrace the change, embrace failure, but do it in an incremental fashion. Small steps, each one focused on partial delivery. That way, success is assured.&lt;/p&gt;</content><category term="Software, Change"></category><category term="TDD"></category><category term="CI"></category></entry></feed>