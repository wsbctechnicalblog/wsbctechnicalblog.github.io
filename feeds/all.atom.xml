<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title></title><link href="https://wsbctechnicalblog.github.io/" rel="alternate"></link><link href="https://wsbctechnicalblog.github.io/feeds/all.atom.xml" rel="self"></link><id>https://wsbctechnicalblog.github.io/</id><updated>2020-10-15T10:20:00-07:00</updated><entry><title>Benefits of frequent deployments</title><link href="https://wsbctechnicalblog.github.io/benefits-of-frequent-deployments.html" rel="alternate"></link><published>2020-10-15T10:20:00-07:00</published><updated>2020-10-15T10:20:00-07:00</updated><author><name>Alex Bunardzic</name></author><id>tag:wsbctechnicalblog.github.io,2020-10-15:/benefits-of-frequent-deployments.html</id><summary type="html">&lt;p&gt;The longer the wait to deploy, the bigger the risk of things going south&lt;/p&gt;</summary><content type="html">&lt;p&gt;I come from the old school software engineering (started my first programming job back in 1990). Thirty years ago, we were building software the same way we always build high rise buildings. We first obtain the fully fleshed budget and the permission to build. We then wait on the blueprints (requirements) to be signed, sealed and delivered, and then start our ‘brick laying’ work. When we finish building, we ask building inspectors to perform due diligence and confirm if the building is suitable to be put on the market.&lt;/p&gt;
&lt;p&gt;Only after all the above activities get successfully completed do we open up our brand new building. We now let people move in.&lt;/p&gt;
&lt;p&gt;In the world of software engineering, the equivalent of moving in would be the event of deploying our app to production. Naturally, the grand opening can happen only once, after which we move into the ‘keeping the lights on’ phase (i.e. maintenance).&lt;/p&gt;
&lt;p&gt;We call this development model “waterfall” (or, “Big Plan Upfront”).&lt;/p&gt;
&lt;h2&gt;Current situation&lt;/h2&gt;
&lt;p&gt;I’ve tried to plot the workflow that may come close to how we are dealing with the deployment workflow today. We start by pulling a story from our backlog. We estimate the story, schedule it for development, and then develop (implement) it. Once we’re ‘code complete’ we commit the code and push it. We then open a PR and if there are issues/problems, the PR gets rejected and the task of fixing the issue goes back to development.&lt;/p&gt;
&lt;p&gt;Eventually, when the PR gets approved and the branch merged, if there are no issues the merged code (release candidate) goes into UAT. If there are no problems in UAT, release candidate gets deployed to production.&lt;/p&gt;
&lt;p&gt;The real headaches occur when we encounter problems in UAT or in production. These problems must be handled manually (with tedious manual verifications), and the fix to the problem is always very disruptive. To apply the fix, we must stop the server(s) in order to deploy the code. That event destroys all users’ sessions; all user data gets irrevocably lost at that moment. After fixing and re-deploying, we force users to sign in again and start all over, and in general the team goes through a very stressful, even traumatic episode.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Old school deploymeny workflow" src="/images/old-school-deployment.png"&gt;&lt;/p&gt;
&lt;h2&gt;Why high levels of stress?&lt;/h2&gt;
&lt;p&gt;Regardless of the circumstances, it always feels terrible to kick users out of the app while they are in the middle of doing important processing. For that reason, we always prefer to schedule deployments for afterhours. However, that’s often times out of the question because the bug is causing terrible damage to production data and needs to be fixed right away.&lt;/p&gt;
&lt;p&gt;Even if we can afford to wait for the afterhours deployment, it is still stressful because we need to schedule for overtime operations staff to work long hours.&lt;/p&gt;
&lt;h2&gt;What is causing this stressful situation?&lt;/h2&gt;
&lt;p&gt;The reason we find ourselves in an unenviable position of having to fix the defects by harming the end user experience lies in the waterfall model. Unlike the engineering workflow that manages the building of physical objects (such as a high rise building), software is not well suited for the waterfall approach. When building physical objects, it is intuitively obvious that there must be an orderly sequence of events (i.e. impossible to work on building a roof of the house if the foundation and the walls are not finished). When developing software, those concerns are not a constraint.&lt;/p&gt;
&lt;p&gt;Still, the classical engineering mentality tends to get carried over to software engineering. Same as we cannot deliver a partially completed foundation and then deliver partially completed walls etc., the mindset that gets carried over to software engineering insists that all the constituent parts of the solution must be fully fleshed out. That means that rework is not allowed – rework is extremely risky.&lt;/p&gt;
&lt;p&gt;In the world of software development, it is actually advisable to focus on partial delivery. Partial delivery implies rework (if something is partial, that means we need to work some more on it).&lt;/p&gt;
&lt;p&gt;The waterfall workflow denies rework, and is therefore very disturbed if, after delivering a fully fleshed product, something turns out to be defective. This is due to the fact that in the world of waterfall workflow, failure is not an option. Everything must be delivered fully completed on the first try, because there won’t be any second chance (i.e. second chance was not factored in the budget). Therefore, when something malfunctions, all hell breaks loose. It wasn’t part of the original plan!&lt;/p&gt;
&lt;h2&gt;How to remove stress from deployment?&lt;/h2&gt;
&lt;p&gt;In order to minimize and even remove the stress, we must modify the deployment workflow. We must move away from the waterfall model, and into a full blown rework model (where second chances are baked in from the get go).&lt;/p&gt;
&lt;p&gt;Let’s examine an aspirational deployment workflow (something I sketched while wearing my optimistic hat):&lt;/p&gt;
&lt;p&gt;&lt;img alt="Deployment workflow" src="/images/deployment-workflow.png"&gt;&lt;/p&gt;
&lt;p&gt;The process starts from the hypothesis (supplied by the business in the form of a user story). We pull one high priority story from the backlog and slice it vertically. We then work on implementing the vertical slice by doing full blown CI/TDD. If we encounter any problems we go back to the user story and refine it. We do all that work by making sure we perform very frequent commits.&lt;/p&gt;
&lt;p&gt;When done, we push the changed code to the remote repo and open a PR. If there is a problem with our PR (problem detected by automated tests and linters), it’s back to the drawing board. Eventually our PR gets approved and merged. The merge event signals to the team that absolutely all quality checks have been cleared; our code is good to go.&lt;/p&gt;
&lt;p&gt;Next step is to automatically deploy the code to production. Gasp! No, it’s not a typo – we should be free, at any time, to deploy fully tested code to production. However, just because the code is deployed doesn’t automatically mean it is available to end users. We always hide the changes from the users behind feature flags.&lt;/p&gt;
&lt;p&gt;Now that our newly minted code is in production, we engage in monitoring its behaviour. We do it by optimizing system observability (collecting and logging telemetry). The production logs should give us sufficient transparency to know whether the code is a solid release candidate or not.&lt;/p&gt;
&lt;p&gt;If we discover the problem in production (luckily, no skin off anyone’s nose thanks to feature flags), we open a ticket/spec to go back to development. Write more tests, write more imposters, fix the problem and push the fix through the automated gatekeepers.&lt;/p&gt;
&lt;p&gt;Eventually, once the problem is resolved, we release to production. And if despite all precautions we still encounter issues in production, we quickly repeat the automated workflow.&lt;/p&gt;
&lt;p&gt;And because all the fixes to the production bugs are going in via feature flags, there is no need to stop and restart the servers. Also, no user session data gets lost; users merely get rerouted to the new code by flipping the feature flags.&lt;/p&gt;
&lt;h2&gt;Why are frequent deployments so beneficial?&lt;/h2&gt;
&lt;p&gt;Finally, let’s discuss the merits of frequent deployments. Once we remove the stress factor from the deployment process, we should freely engage in deploying as often as possible.&lt;/p&gt;
&lt;p&gt;Why would we want to do that? Frequent deployments teach us invaluable lessons about our market, about our system, about our features. We cannot know whether our changes make sense or not unless we put them out in the field. No focus group can give us accurate prediction on how will a change to the system behave once it goes live.&lt;/p&gt;
&lt;p&gt;As the saying goes, the proof is in the pudding.&lt;/p&gt;</content><category term="Posts"></category><category term="TDD"></category><category term="CI"></category></entry><entry><title>Hypothesis-Driven Development</title><link href="https://wsbctechnicalblog.github.io/hypothesis-driven-development.html" rel="alternate"></link><published>2020-10-13T12:20:00-07:00</published><updated>2020-10-13T12:20:00-07:00</updated><author><name>Alex Bunardzic</name></author><id>tag:wsbctechnicalblog.github.io,2020-10-13:/hypothesis-driven-development.html</id><summary type="html">&lt;p&gt;Developing a feature without formulating a hypothesis is like shooting in the dark&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;“The only way it’s all going to go according to plan is if you don’t learn anything.”&lt;/em&gt; -Kent Beck&lt;/p&gt;
&lt;p&gt;Experimentation is the foundation of the scientific method, which is a systematic means of exploring the world around us. But experimentation is not only reserved for the field of scientific research. It has its central place in the world of business too.&lt;/p&gt;
&lt;p&gt;Most of us are by now familiar with the business methodology called Minimum Viable Product (&lt;strong&gt;MVP&lt;/strong&gt;). This Minimum Viable Product is basically just an experiment. By building and launching MVPs, business operations are engaging in a systematic means of exploring the markets.&lt;/p&gt;
&lt;p&gt;If we look at market leaders today, we learn that they’re not doing projects anymore. The only thing they’re doing is experiments. &lt;strong&gt;Customer discover&lt;/strong&gt;y&lt;strong&gt; and &lt;/strong&gt;Lean strategies&lt;strong&gt; are used to test assumptions about the markets. Such approach is equivalent to Test-Driven Development (&lt;/strong&gt;TDD**), which is the process we are intimately familiar with. In TDD, we write the hypothesis first (the test). We then use that test to guide our implementation. Ultimately, product or service development is no different than TDD – we first write a hypothesis, that hypothesis guides our implementation which serves as measurable validation of the hypothesis.&lt;/p&gt;
&lt;h2&gt;Information discovery&lt;/h2&gt;
&lt;p&gt;Back in the pre-agile days, requirements gathering was an important activity that used to always kick-off the project. A bunch of SMEs used to get assigned on the project, and were tasked with gathering the requirements. After a prolonged period of upfront information discovery, the gathered requirements got reviewed and, if agreed upon, signed off and frozen. No more changes allowed!&lt;/p&gt;
&lt;p&gt;Back then it seemed a perfectly reasonable thing to do. The fly in the ointment always kicked in once the build phase commenced. Sooner or later, as the project progresses, new information comes into the light of day. Suddenly, what we initially held as incontrovertible truth, gets challenged by the newly acquired information and evidence.&lt;/p&gt;
&lt;p&gt;But the clincher was in the gated phases. Remember, once requirements get signed off, they get frozen. No more changes, no scope creep allowed. Which means, newly obtained market insights get willfully ignored.&lt;/p&gt;
&lt;p&gt;Well, that’s kind of a foolish neglect. More often than not, the newly emerging evidence could be of critical importance to the health of the business operation. Can we afford to ignore it? You be we cannot! We have no recourse other than to embrace the change.&lt;/p&gt;
&lt;p&gt;It is after a number of prominent fiascos in the industry that many software development projects switched to the agile approach. With agile, information discovery is partial. With agile we never claim that we have gathered the requirements, and are now ready to implement them. We keep discovering information and implementing it at the same time (we embrace the change). We do it in tiny steps, keeping our efforts interruptible and steerable at all times.&lt;/p&gt;
&lt;p&gt;How to leverage the scientific method&lt;/p&gt;
&lt;p&gt;Scientific method is empirical and consists of performing the following steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Step 1: make and record careful observations&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 2: perform orientation with regards to observed evidence&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 3: formulate a hypothesis, including measurable indicators for hypothesis evaluation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 4: design an experiment that will enable us to test the hypothesis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 5: conduct the experiment (i.e. release the partial implementation)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 6: collect the telemetry that results from running the experiment&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 7: evaluate the results of the experiment&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 8: accept or reject the hypothesis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 9: go to Step 1&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;How to formulate a hypothesis&lt;/h2&gt;
&lt;p&gt;When switching from projects to experiments, traditional user story framework (As a/I want to/So that) is proving insufficient. The traditional user story format does not expose the signals needed in order to evaluate the outcomes. Instead, old school user story format is focused on outputs.&lt;/p&gt;
&lt;p&gt;The problem with doing an experiment without first formulating a hypothesis is that there is a danger of introducing a bias when interpreting the results of an experiment. Defining the measurable signals that will enable us to corroborate our hypothesis must be done before we conduct the experiment. That way, we can remain completely impartial when interpreting the results of the experiment. We cannot be swayed by wishful thinking.&lt;/p&gt;
&lt;p&gt;The best way to proceed with formulating a hypothesis is to use the following format:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We believe&lt;/strong&gt; [this capability]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Will result in&lt;/strong&gt; [this outcome]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We will have the confidence to proceed when&lt;/strong&gt; [we see a measurable signal]&lt;/p&gt;
&lt;h2&gt;Working software is not a measure of progress&lt;/h2&gt;
&lt;p&gt;Output-based metrics and concepts (Definition of Done, acceptance criteria, burndown charts, and velocity) are good for detecting working software, but fall miserably when it comes to detecting if working software adds value.&lt;/p&gt;
&lt;p&gt;“Done” only matters if it adds value. Working software that doesn’t add value cannot be declared “done”.&lt;/p&gt;
&lt;h2&gt;The forgotten column&lt;/h2&gt;
&lt;p&gt;Technology-centric projects break activities down into four columns:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Backlog of ideas&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Analysis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In progress&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shipped&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The above structure is based on the strong belief that all software that works is valuable. That focus must now shift toward continuously delivering real value, something that serves customers. Agilists value outcomes (value to the customers) over features.&lt;/p&gt;
&lt;p&gt;The new breakdown for hypothesis-driven development looks something like this:&lt;/p&gt;
&lt;table&gt;
&lt;tr&gt;
  &lt;th&gt;
    &lt;td&gt;&lt;strong&gt;Ideas backlog&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt;&lt;strong&gt;Analysis&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt;&lt;strong&gt;In progress&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt;&lt;strong&gt;Shipped&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt;&lt;strong&gt;Achieved desired outcome&lt;/strong&gt;&lt;/td&gt;
  &lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
  &lt;td&gt;Hypothesis 11&lt;/td&gt;&lt;td&gt;Hypothesis 20&lt;/td&gt;&lt;td&gt;Hypothesis 26&lt;/td&gt;&lt;td&gt;Hypothesis 1&lt;/td&gt;&lt;td&gt;Hypothesis 1&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
  &lt;td&gt;Hypothesis 12&lt;/td&gt;&lt;td&gt;Hypothesis 21&lt;/td&gt;&lt;td&gt;Hypothesis 5&lt;/td&gt;&lt;td&gt;Hypothesis 5&lt;/td&gt;&lt;td&gt;Hypothesis 5&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
  &lt;td&gt;Hypothesis 13&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;Hypothesis 10&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
  &lt;td&gt;Hypothesis 14&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
  &lt;td&gt;Hypothesis 15&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
  &lt;td&gt;Hypothesis 16&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
  &lt;td&gt;Hypothesis 17&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
  &lt;td&gt;Hypothesis 18&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;
  &lt;td&gt;Hypothesis 19&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;All eyes must remain peeled on the &lt;strong&gt;Achieved desired outcome&lt;/strong&gt;.&lt;/p&gt;</content><category term="Posts"></category><category term="TDD"></category><category term="CI"></category></entry><entry><title>The cost of avoiding change</title><link href="https://wsbctechnicalblog.github.io/the-cost-of-avoiding-change.html" rel="alternate"></link><published>2020-10-03T10:20:00-07:00</published><updated>2020-10-03T10:20:00-07:00</updated><author><name>Alex Bunardzic</name></author><id>tag:wsbctechnicalblog.github.io,2020-10-03:/the-cost-of-avoiding-change.html</id><summary type="html">&lt;p&gt;Change is stressful and risky, but avoing it is even riskier&lt;/p&gt;</summary><content type="html">&lt;p&gt;Software engineers are notorious for being averse to change. We prefer the steady state, stability. The reason we prefer steady state lies in the fact that systems we are building tend to be complex. Complexity breeds brittleness, and so we are keen on doing everything possible to avoid building brittle systems. Who could blame us?&lt;/p&gt;
&lt;h2&gt;City on the Hill&lt;/h2&gt;
&lt;p&gt;When engineering a system, we tend to think about it in terms of an endpoint (let’s call that endpoint City on the Hill). This idealized city needs to be defined rigorously. After all, that’s what engineering is all about – rigor.&lt;/p&gt;
&lt;p&gt;After we’ve defined it, we optimize the process of building it offline. Once it’s built, we confirm that it’s done (using our Definition of Done yardstick). We then push it online, move into it, and never change it again (if we need to make any changes, we’d be admitting that we haven’t defined it rigorously to begin with).&lt;/p&gt;
&lt;h2&gt;Efficiency&lt;/h2&gt;
&lt;p&gt;The central idea of efficiency is that changing something is a waste. Why did we build the thing in the first place if we are to turn around and change it? Wouldn’t doing that mean that we didn’t actually know how to build our City on the Hill? Why not build our system correctly to begin with? Anything else would be grossly inefficient.&lt;/p&gt;
&lt;h2&gt;Change is bad&lt;/h2&gt;
&lt;p&gt;According to the above reasoning, change is bad. It is wasteful and inefficient. Pushed to its limit, this ‘change is bad’ sentiment blossoms into full-blown ‘change is to be feared’ mindset.&lt;/p&gt;
&lt;p&gt;Our City on the Hill ideal implies finality. Upon reaching our final destination, the reason to ever consider change is only if we realize that we have hit the wrong target. And that means utmost defeat (the ultimate inefficiency and waste).&lt;/p&gt;
&lt;h2&gt;All complexity at the beginning and all reward at the end&lt;/h2&gt;
&lt;p&gt;The City on the Hill approach to software engineering makes our profession extremely hard. We frontload all the complexity at the very beginning of the project. We ‘kitchen sink’ the project: since we only get one shot to make it right, we’d better create a laundry list of all the features we will ever need.&lt;/p&gt;
&lt;p&gt;Working on the detailed laundry list of all the features is a complex process. And it does not deliver any rewards. It may take days, weeks, even months to get to the end of job. And once we get there, we reap no rewards. All we have to show for is a pile of documents and diagrams – zero shippable software. The work on building shippable software has yet to commence. And it is only at the very end, once we ship the finished City on the Hill product, that we get any rewards for this gargantuan effort.&lt;/p&gt;
&lt;h2&gt;Gold-plating the parts&lt;/h2&gt;
&lt;p&gt;The pressure of having only one shot at building our City on the Hill forces us to gold-plate all parts we’re building. We feel compelled to make each part better than it has to be in order to do its job. We are at that point playing the prediction game – maybe in the future this function will have to be integrated with another system, and because we won’t be making any changes to it later on, let’s make sure now it is sufficiently generalized. Or, add those bells and whistles that only one in thousand users ever notices, let alone makes any use of it.&lt;/p&gt;
&lt;h2&gt;Fear of imperfections&lt;/h2&gt;
&lt;p&gt;The ‘kitchen sink’ laundry list of features, where each part must be gold-plated, results in code that is far more complex than it needs to be. That naturally leads to lack of understanding. Lack of understanding leads to lack of confidence. That lack of confidence makes development slower because of the looming finality – do it once and make sure you do it right!&lt;/p&gt;
&lt;p&gt;Such attitude results in the fear of imperfection. The fear of being wrong tends to lead to paralysis. Suddenly, the stakes of any decision made by the engineers seem incredibly high. Trying things and experimenting is viewed as wasting precious time and resources.&lt;/p&gt;
&lt;h2&gt;Death march&lt;/h2&gt;
&lt;p&gt;The finality of the City on the Hill approach leads to very late validation. By the time we catch any issues with our gold-plated parts and how they struggle to integrate, the goodwill has already been largely spent. All the hard work invested in taming considerable complexities rarely pays off if we adopt the ‘failure is not an option’ mentality.&lt;/p&gt;
&lt;p&gt;We cannot confirm whether the code we’re building actually implements our City until all pieces are in. Five-to-midnight is the worst time to discover we have problems. That is the point of maximum stress, as we are on the collision course to our deadline.&lt;/p&gt;
&lt;h2&gt;Break the workload into parallel chunks?&lt;/h2&gt;
&lt;p&gt;To avoid the looming death march described above, we often see workload being divided into independent chunks to be worked on in parallel. Sounds reasonable on the surface, until we take a closer look and factor-in the cost of control needed to coordinate and synchronize independent strains of work. Managing that kind of parallelism is a tall order. Out of sheer necessity, management introduces ‘wait states’ and ‘sync points’. The independent development suddenly ceases to be independent, as it must become strictly lockstep. Copious documents, emails, tickets and handoffs start proliferating, slowing everything down to a crawl.&lt;/p&gt;
&lt;h2&gt;Rework Avoidance&lt;/h2&gt;
&lt;p&gt;Avoiding change leads to avoiding rework. Any attempt at making something must be done in such a way that there would never be any need for rework. Make it right from the get go, on the first attempt.&lt;/p&gt;
&lt;p&gt;The cost of avoiding rework is best expressed in the cost of late failures. Those dreadful five-to-midnight failures are extremely costly; not only that, but they leave very little room for rework. By the time we realize that things are not gelling as expected, it is often too late for attempting any rework.&lt;/p&gt;
&lt;h2&gt;Switch to partial delivery&lt;/h2&gt;
&lt;p&gt;In order to evade the exorbitant cost of rework avoidance, we must pivot and embrace change via partial delivery. Embracing change necessitates innovation, experimenting, trying things out. The only way to do that effectively is to cultivate the ‘fail early’ mindset. Failure is desirable because it prompts us to fix it while it is still easy to do so.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Avoiding change, while very tempting and perfectly natural, usually ends up being very costly. Fear of failure is preventing innovation and experimentation by stifling change. The only way to avoid paying such exorbitant price is to embrace the change, embrace failure, but do it in an incremental fashion. Small steps, each one focused on partial delivery. That way, success is assured.&lt;/p&gt;</content><category term="Posts"></category><category term="TDD"></category><category term="CI"></category></entry><entry><title>Feature-flag Driven Development (FFDD)</title><link href="https://wsbctechnicalblog.github.io/feature-flag-driven-development.html" rel="alternate"></link><published>2020-09-04T11:10:00-07:00</published><updated>2020-09-04T11:10:00-07:00</updated><author><name>Alex Bunardzic</name></author><id>tag:wsbctechnicalblog.github.io,2020-09-04:/feature-flag-driven-development.html</id><summary type="html">&lt;p&gt;Replace physical modularity with logical modularity&lt;/p&gt;</summary><content type="html">&lt;p&gt;Experts say that repo branching workflow is poor man’s modularization (by experts I mostly refer to Martin Fowler and his team of deep thinkers). What do we mean by branching being poor man’s modularization?&lt;/p&gt;
&lt;h2&gt;Well modularized repo&lt;/h2&gt;
&lt;p&gt;Let’s examine how change management propagates in a repo that has been properly modularized from the get go:&lt;/p&gt;
&lt;p&gt;A new feature needs to be added to the product, which necessitates change to the codebase. Because the code is fully modularized, it is closed to any changes related to the new feature, but is at the same time open for any changes that would extend its feature set (the Open/Closed Principle, part of the SOLID package).&lt;/p&gt;
&lt;p&gt;The new feature will thus be coded by adding brand new modules. Barely any line of existing code will have to be modified, since the new feature would be a plugin.&lt;/p&gt;
&lt;h2&gt;Poorly modularized repo&lt;/h2&gt;
&lt;p&gt;A code that is poorly modularized will have to be modified (sometimes heavily) in order to introduce a new feature into the product.&lt;/p&gt;
&lt;p&gt;Any time two or more people are working on the same block of code, they introduce a moving target. Changes made to the same codebase may result in a conflict. That conflict potentially arises at the time when we are trying to retrofit new code into the existing codebase. Those are the dreaded merge conflicts.&lt;/p&gt;
&lt;h2&gt;Why do we branch in the first place?&lt;/h2&gt;
&lt;p&gt;The main reason we copy the existing code base and turn it into a feature branch is to protect the healthy master branch from getting corrupted. Teamwork often necessitates that two or more feature branches get created during sprint, and that means that there is an ongoing work that is happening in parallel. When the time comes to bring the new changes to the healthy branch, some of those new changes may mutually collide.&lt;/p&gt;
&lt;p&gt;So the caution we exercise by branching is introducing unwanted risks of creating merge conflicts.&lt;/p&gt;
&lt;h2&gt;How to avoid merge conflicts?&lt;/h2&gt;
&lt;p&gt;During the workflow described above, it is not really possible to avoid potential merge conflicts. But we can certainly minimize potential conflicts.&lt;/p&gt;
&lt;p&gt;It all boils down to timing. When we take a copy of the healthy branch and go away and begin making changes to the code, the clock starts ticking. The longer we wait to bring our changes to the healthy branch, the greater that chances that someone else had already made changes to it that may collide with our changes.&lt;/p&gt;
&lt;p&gt;That is one of the main reasons why best practices advocate short-lived branches. The shorter the lifespan of a branch, the smaller the risk of having merge conflicts. And lesser merge conflicts mean quicker value delivery and lesser churn.&lt;/p&gt;
&lt;p&gt;And of course, merge conflicts are of much lower possibility in well modularized codebases, as we have already discussed above.&lt;/p&gt;
&lt;h2&gt;Feature flags&lt;/h2&gt;
&lt;p&gt;Much as Martin Fowler et al claim that branching is poor man’s modularization, it is also possible to say that branching is poor man’s feature flags. So what are feature flags?&lt;/p&gt;
&lt;p&gt;Feature flags could be viewed as logical branching. While physical branches, as they are practiced in modern engineering mostly using git, require making a physical copy of the repo and giving it a unique name, feature flags could be used without necessarily having to make a physical copy. When using Feature-Flag Driven Development (FFDD), we simply leave the existing code intact and write new modules that get conditionally called. The conditional logic is binary, and is governed by the feature flag (which could be either in on or in off state). If the flag is in the on state, the new code will get executed. Otherwise, execution continues as usual (old code runs).&lt;/p&gt;
&lt;p&gt;FFDD enables us to add potentially risky changes to the healthy codebase, without going through the song and dance of trying to merge the changes and risking merge conflicts. This technique then enables us to quickly ship new features in stealth mode. Our regular customer population will not get affected, since they will still be using the old, tested codebase. But our QA can then safely assess and evaluate the risks and potential merits of the new code. That activity would be the equivalent of the Pull Request in the branch-driven development discipline. If the PR of the code under the feature flag passes the muster, the old code gets decommissioned and the new code becomes the healthy version of the codebase.&lt;/p&gt;</content><category term="Posts"></category><category term="Feature-flag"></category></entry></feed>